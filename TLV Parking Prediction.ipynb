{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "We are Guy Halevi and Orr Jungerman, final-year students with great interest in data science. We chose this workshop to extend our knowledge and practice major data science principles.\n",
    "It's worth noting we live close to each other in middle-north Tel-Aviv (Old North neighborhood), a district notoriously known to lack parking options.\n",
    "When we were tasked with choosing a topic for this project, we wanted to tackle something important and beneficial for us. Thus, predicting parking in some way was one of the first ideas coming to mind.\n",
    "Luckily, we have been harvesting parking data about few parking lots for quite some time.\n",
    "\n",
    "\n",
    "# The Problem\n",
    "\n",
    "Our experience with parking lots in Tel-Aviv led us to believe that there are common recurring patterns. For example, on weekdays most parking lots are emptying in the morning and filling up at the evening due to day jobs. On the contrary, on weekends the parking lots tend to empty much later since most of the residents are not working and driving back to their families.\n",
    "To back our experience with real and objective data, we have been collecting for the past 2 years the vacancy status of popular parking lots, on a per-minute basis.\n",
    "We believe we can use this data to accurately predict the status of each parking lot, helping us to plan ahead our schedule.\n",
    "We expect to find interesting anomalies due to holidays or special events (such as lockdowns, rain, etc.). To deal with such anomalies, we will enrich the data with more information such as recurring holidays and more.\n",
    "\n",
    "\n",
    "\n",
    "# Our Data\n",
    "The data we collected comes in a CSV format, where each row contains the vacancy status of 6 different parking lots at specific time.\n",
    "The parking lots are: Basel, Asuta, Sheraton, Dan, Dubnov and Habima.\n",
    "There are 6 different vacancy statuses: Free - significant number of spots, Few - parking lot is almost full, Full - no spots at all, Active - no indication at that time, Unknown/NaN - we had trouble collecting the status.\n",
    "We started collecting data since July 19, with minute resolution. We managed to collect the data by writing a simple script that parses the website of each parking lot, for example http://www.ahuzot.co.il/Parking/ParkingDetails/?ID=3.\n",
    "\n",
    "The following map shows the locations of the 6 lots:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](lots.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime, date, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import HTML\n",
    "from more_itertools import first\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "tqdm.pandas()\n",
    "np.random.seed(0)\n",
    "RANDOM_STATE=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "\n",
    "LOT_NAMES = ['Basel', 'Asuta', 'Sheraton', 'Dan', 'Dubnov', 'Habima']\n",
    "DATA_CSV_FILENAME = 'june21_parks.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by viewing the raw data.<br>\n",
    "We will use pandas to load the CSV into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(DATA_CSV_FILENAME)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Assesment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will copy our raw data, so we can modify the copy without altering the original data.\n",
    "\n",
    "Let's change column names to more standard and conventient names, and set the right types to each column in order to be able to use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = raw_df.copy()\n",
    "full_df = full_df.rename(columns={\n",
    "    'Day': 'day',\n",
    "    'Hour': 'hour',\n",
    "    'Minute': 'minute',\n",
    "    'Date': 'date'\n",
    "})\n",
    "full_df['datetime'] = full_df['date'] + \" \" + full_df[\"hour\"].astype(str) + \":\" + full_df[\"minute\"].astype(str)\n",
    "full_df['datetime'] = pd.to_datetime(full_df['datetime'], format='%d/%m/%Y %H:%M')\n",
    "full_df['datetime'] = full_df['datetime'].dt.tz_localize('Asia/Jerusalem', 'infer')\n",
    "full_df.pop('date')\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `datetime` column is now recognized as a date object instead of a simple string.\n",
    "\n",
    "Now, let's explore the \"parking statuses\", or classes in our terminology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[LOT_NAMES].apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in addition to the 3 main statuses <`Free`, `Few`, `Full`>, there are 3 additional \"unknown\" statuses that are quite rare which we want to exclude from our dataset - <`NaN`, `Active`, `Unknown`>.\n",
    "\n",
    "In addition to excluding the 3 \"unknown\" statuses, we need to decide how to handle the 3 \"main\" statuses.\n",
    "The meaning of `Few` is that there are some parking spots available, but just a few. It means that in some cases, if we checked the status a few seconds earlier or later than we actually did, we would have been able to get different results. So, it makes sense to smooth the data. For example, if the status was `Full` for a while, then `Few` for a few minutes and then `Full` again, it makes more sense to translate this `Few` to `Full` than to `Free`, and the same for the other way around.\n",
    "\n",
    "In order to do that, we will start by treating `Few` as \"the middle between `Free` and `Full`\", or in other words, we will translate `Free -> 1`, `Few -> 0.5`, `Full -> 0`, as `Free` has 1 (a lot) of free parking, `Few` has 0.5 (few) free parking and `Full` has 0 (no) free parking.<br>\n",
    "Later we will normalize each `0.5` point to either `0` or `1`, depending on its surroundings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lot in LOT_NAMES:\n",
    "    full_df[lot] = full_df[lot].replace({\n",
    "        'Unknown': np.nan,\n",
    "        'Active': np.nan,\n",
    "        'Free': 1,\n",
    "        'Few': 0.5,\n",
    "        'Full': 0,\n",
    "    }, inplace=False)\n",
    "\n",
    "print('Full dataset:')\n",
    "display(full_df)\n",
    "print('Classes:')\n",
    "display(full_df[LOT_NAMES].apply(pd.value_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work with the data, it would be much more convenient if each row had only one class.<br>\n",
    "In addition, we will remove rows with the class `NaN` so that our data is clean. We didn't do it before to avoid removing a complete row because of one missing value at one parking lot.<br>\n",
    "We use `melt()` to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df = (\n",
    "    full_df\n",
    "    .melt(\n",
    "        id_vars=[\n",
    "            'datetime',\n",
    "            'day',\n",
    "            'hour',\n",
    "            'minute',\n",
    "        ],\n",
    "        var_name='lot',\n",
    "        value_name='class'\n",
    "    )\n",
    "    .dropna()\n",
    ")\n",
    "melted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data resampling\n",
    "Our dataset is incomplete - sometimes the scraper didn't run and sometimes there were problems with the API. However, we can try to rectify some of the lost data by resampling and applying a moving average. This approach will also help us to reduce noise and small anomalies.<br>\n",
    "Using moving average, the discrete availability class becomes a continious variable of the parking availability likelihood at that point of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample to 1m\n",
    "resampled_df = melted_df.set_index('datetime').groupby('lot').resample('60s').first()\n",
    "\n",
    "# Drop `lot` column - upsampled datapoints are set to na, including lot\n",
    "resampled_df = resampled_df.drop(columns=['lot'])\n",
    "\n",
    "# Ungroup, so all the samples get the proper lot and datetime values\n",
    "resampled_df = resampled_df.reset_index()\n",
    "\n",
    "# Group upsampled data by lot\n",
    "avg_df = resampled_df.groupby(by=['lot'])\n",
    "\n",
    "# Apply moving average on upsampled data\n",
    "avg_df = avg_df.rolling('1h', on='datetime', min_periods=5, center=True, win_type='gaussian')['class'].mean(std=0.5)\n",
    "\n",
    "# Drop data points that we could not decide their availability\n",
    "avg_df = avg_df.dropna().reset_index()\n",
    "\n",
    "#Rename class column to availability\n",
    "avg_df = avg_df.rename(columns={\"class\": \"availability\"})\n",
    "\n",
    "print(f\"number of original samples: {len(melted_df)}\")\n",
    "print(f\"number of resampled samples: {len(avg_df)}\")\n",
    "print(f\"rectified: {len(avg_df) - len(melted_df)} samples\")\n",
    "\n",
    "avg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold and Downsample\n",
    "After we applied a moving average resulting in the availability feature, we'd like to define a threshold for parking status classification.\n",
    "Since `Few` status was translated as `0.5`, we believe it should act as the threshold nubmer too.<br>\n",
    "Every hour that its average is lower than `0.5` is an hour that was `Full` most of the time and will be normalized to `0`, and every hour that is higher than `0.5` will be normalized to `1`.<br>\n",
    "Regarding hours with an average of exactly `0.5`, we decided to treat them as `Free` (i.e. `0`), as it means that for a whole hour, most of the times there were \"at least a few spots available\".<br>\n",
    "For computational reasons and simplicity of the data analysis, we decided to downsample the dataset to 1H."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df['class'] = (avg_df['availability'] >= 0.5).astype(int)\n",
    "avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_df = avg_df[avg_df['datetime'].dt.minute == 0].copy()\n",
    "hourly_df['datehour'] = hourly_df['datetime'].dt.date.astype(str) + \" - \" + hourly_df['datetime'].dt.hour.astype(str).str.zfill(2)\n",
    "hourly_df = hourly_df.set_index('datehour')\n",
    "hourly_df['date'] = hourly_df['datetime'].dt.normalize()\n",
    "hourly_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the part where we want to visualize our data. The visualizations are supposes to give us a grasp on our data and validate our hypothesis. \n",
    "\n",
    "Let's start by visualizing the classes distribution among the different lots.<br>\n",
    "We will use a color palette that gives us the right intuition - 1 is \"good\" (there are free parking spots!), therefore green, and 0 is \"bad\", therefore red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREEN_RED_PALETTE = {1.0: 'green', 0.0: 'red'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "\n",
    "_ = sns.histplot(\n",
    "    data=hourly_df,\n",
    "    x='lot',\n",
    "    hue='class',\n",
    "    multiple='dodge',\n",
    "    palette=GREEN_RED_PALETTE,\n",
    "    shrink=0.7,\n",
    ").set_title('Class Distribution Per Parking Lot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the histogram shows, some lots have relatively equally distributed classes (e.g. Basel), while some have almost only one class (e.g. Habima).\n",
    "\n",
    "We can also see that `Free` is the most common class in all lots.<br>\n",
    "It's already some interesting information for us, as we personally feel like Basel, the one that's closest to where we both live.\n",
    "<br><br><br>\n",
    "We'd like to mention how difficult it is to visualize the data in a way that makes sense and that is intuitive. We tried many methods but all showed too much information that was not helpful in any way.\n",
    "\n",
    "For example, let's show classes over time, for one specific month - January 2020:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "\n",
    "sns.lineplot(\n",
    "    marker='o',\n",
    "    x='date',\n",
    "    y='class',\n",
    "    hue='lot',\n",
    "    data=hourly_df[(hourly_df['datetime'].dt.year == 2020) & (hourly_df['datetime'].dt.month == 1)],\n",
    ")\n",
    "\n",
    "\n",
    "for item in plt.xticks()[1]:\n",
    "    item.set_rotation(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, even after we filter out most data and stay with only one month of data (out of ~2 years that we have!) is too much for visualizing without any special treatment.\n",
    "\n",
    "Then we came up with the idea of weekly patterns. As mentioned before, we believe the parking vacancy status recurrs every week. Let's transform our data to validate this hypothesis.\n",
    "\n",
    "### Weekly Patterns\n",
    "From our own knowledge and experience, we know that available parking spots change over the week in a periodic way that is very similar between different weeks. For example, every morning in the week days there is quite a lot of parking, and every evening there isn't. In the weekends it changes; Friday morning is busy but Friday evening is always super free (as most young people visit their parents outside of Tel Aviv, probably).\n",
    "\n",
    "It's a very interesting hypothesis to start with.<br>\n",
    "Let's use FFT (Fast Fourier Transform) to prove that these patterns actually exist:\n",
    "#### FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_df = hourly_df.copy().reset_index().set_index('datetime')['class']\n",
    "fft_df = fft_df.resample('1h').first()\n",
    "# fft ignores random noise\n",
    "fft_df = fft_df.apply(lambda l: l if not np.isnan(l) else np.random.random())\n",
    "\n",
    "fft = tf.signal.rfft(fft_df)\n",
    "freqs = np.arange(0, len(fft))\n",
    "total_hours = len(fft_df)\n",
    "hours_in_week = 7 * 24\n",
    "steps = freqs / total_hours * hours_in_week\n",
    "\n",
    "plt.step(steps, np.abs(fft))\n",
    "plt.xscale('log')\n",
    "plt.ylim(0, 3000)\n",
    "plt.xlim([0.2, 7 * 24]) # Limits to about 1/month - 1/hour\n",
    "_ = plt.xticks([14, 7, 1], labels=['1 / 12-hours', '1 / day', '1 / week'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FFT diagram definitely shows that there is a significant recurring pattern every day (which means that the time of day is very correlated to the parking availability status) and a smaller spike, yet still visible and significant, every week (which means that the day of the week is correlated with the status).\n",
    "\n",
    "We expected the weekly pattern to be more significant, but we assume it's not as significant as we expected because we expect all 5 weekdays to be quite the same, and only weekends to be different.\n",
    "<br><br><br>\n",
    "Let's group the data by weeks (every week is defined as 00:00 on Sunday until 23:00 on Saturday). To simplify the data, we drop a few rows that are before the first whole week we have data for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_DAY_OF_FIRST_WHOLE_WEEK = pd.to_datetime(date(year=2019, month=7, day=14)).tz_localize('Asia/Jerusalem')\n",
    "hourly_df = hourly_df[hourly_df['date'] >= FIRST_DAY_OF_FIRST_WHOLE_WEEK].copy()\n",
    "\n",
    "hourly_df['week_first_day'] = (\n",
    "    ((hourly_df['date'] - FIRST_DAY_OF_FIRST_WHOLE_WEEK).dt.days / 7)\n",
    "    .astype(int)\n",
    "    .apply(lambda week_idx: FIRST_DAY_OF_FIRST_WHOLE_WEEK + pd.to_timedelta(timedelta(weeks=week_idx)))\n",
    ")\n",
    "\n",
    "hourly_df['day_hour'] = hourly_df['date'].dt.day_name() + '-' + hourly_df['datetime'].dt.hour.astype(str).str.zfill(2)\n",
    "hourly_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have week information for each row, we can start showing weekly trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(13, 8))\n",
    "fig.suptitle('Average Parking Per Hour In The Week', fontsize=22)\n",
    "gs = fig.add_gridspec(3, 3)\n",
    "axes = [fig.add_subplot(gs[0, :])]\n",
    "for i in range(len(LOT_NAMES)):\n",
    "    axes.append(fig.add_subplot(gs[1 + i // 3, i % 3]))\n",
    "\n",
    "ax = axes[0]\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    x='day_hour',\n",
    "    y='class',\n",
    "    data=hourly_df\n",
    ")\n",
    "ax.set_title('All Lots Combined')\n",
    "\n",
    "for i, lot in enumerate(LOT_NAMES):\n",
    "    ax = axes[i + 1]\n",
    "    g = sns.lineplot(\n",
    "        ax=ax,\n",
    "        x='day_hour',\n",
    "        y='class',\n",
    "        data=hourly_df[hourly_df['lot'] == lot]\n",
    "    )\n",
    "    g.axhline(0.5, color='red')\n",
    "    ax.set_title(lot)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_ylim(bottom=0, top=1)\n",
    "    for i, label in enumerate(ax.get_xticklabels()):\n",
    "        if i % 8 == 0:\n",
    "            label.set_rotation(90)\n",
    "        else:\n",
    "            label.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the visualization is much better and it actually starts to make sense!<br>\n",
    "We finally have our first informative visualization, that supports our hypothesis of weekly trends.\n",
    "\n",
    "Note the width of the lines. The wider the line is, the more variation there is in the classes at that point. We can see that all lines are relatively narrow, especially when comparing to the earlier unsuccessful visualization.<br>\n",
    "The meaning of the narrow lines is that for every hour in a week, its classes are quite similar between all weeks in our data.\n",
    "\n",
    "Even though it's a pretty good start, the visualization does not prove that the data is completely predictable using `lot` and `day_hour` features only. It only shows that it has good correlation.<br><br>\n",
    "\n",
    "Now let's take a look from another point of view.\n",
    "\n",
    "Instead of showing the average parking per hour in the week, among all weeks, let's show the average parking per week over time.<br>\n",
    "To do so, we need to have the average parking status per week over time.\n",
    "\n",
    "We define the parking status of a week as the average of all hours within the week.<br>\n",
    "It's important to note that our `class` will no longer be one of 2 discrete options - it will become a continuous number. We will only use this data for this visualization and then come back to the earlier per-hour format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_df = (\n",
    "    hourly_df\n",
    "    .groupby(by=['week_first_day', 'lot'])\n",
    "    .agg({'class': 'mean'})\n",
    "    .reset_index()\n",
    ")\n",
    "weekly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(13, 8))\n",
    "fig.suptitle('Average Parking Per Week Over Time', fontsize=22)\n",
    "gs = fig.add_gridspec(3, 3)\n",
    "axes = [fig.add_subplot(gs[0, :])]\n",
    "for i in range(len(LOT_NAMES)):\n",
    "    axes.append(fig.add_subplot(gs[1 + i // 3, i % 3]))\n",
    "\n",
    "ax = axes[0]\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    x='week_first_day',\n",
    "    marker='o',\n",
    "    y='class',\n",
    "    data=weekly_df\n",
    ")\n",
    "ax.set_title('All Lots Combined')\n",
    "\n",
    "for i, lot in enumerate(LOT_NAMES):\n",
    "    ax = axes[i + 1]\n",
    "    sns.lineplot(\n",
    "        ax=ax,\n",
    "        x='week_first_day',\n",
    "        marker='o',\n",
    "        y='class',\n",
    "        data=weekly_df[weekly_df['lot'] == lot]\n",
    "    )\n",
    "    ax.set_title(lot)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_ylim(bottom=0, top=1)\n",
    "    for i, label in enumerate(ax.get_xticklabels()):\n",
    "        label.set_rotation(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there have been some changes over time.<br>\n",
    "There are several specific things to take from this view.\n",
    "\n",
    "The first one is that there is a big gap without any data points somewhere between 2020-05 and 2020-07. Not only that, but the next week after the gap is extermely different than usual, mosly to the worse, but not only, and it differs a lot among the different lots as shown by the width of the top line.\n",
    "\n",
    "The second is the variation around 2019-11, as shown by the width of the top line. Some of the parking lots had much more space than usual, and some much less.\n",
    "\n",
    "The third is the two peak points around 2020-04 and 2020-10, in which all lots had unusual big amount of free parking spots.\n",
    "\n",
    "We will try to use these insights later in this project, and will also try to explain them.<br><br>\n",
    "\n",
    "Finally, we had an idea for a visualization that combines most data, and visualizes it in a way that makes much sense and is very intuitive.<br>\n",
    "The idea is to show every week of a specific parking lot as a row of points, each has a color as before (green means `Free`, red means `Full`). To show trends over time, we put weeks above other ones, so that the lowest line is the earliest week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(LOT_NAMES), 1, figsize=(15, 8 * len(LOT_NAMES)), sharey=True)\n",
    "fig.suptitle('Parking Per Hour In The Week Over Time', fontsize=22, y=0.895)\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "for i, lot in enumerate(LOT_NAMES):\n",
    "    ax = axes[i]\n",
    "    plot = sns.scatterplot(\n",
    "        ax=ax,\n",
    "        palette=GREEN_RED_PALETTE,\n",
    "        legend=False,\n",
    "        x='day_hour',\n",
    "        y='week_first_day',\n",
    "        hue='class',\n",
    "        s=10,\n",
    "        data=hourly_df[hourly_df['lot'] == lot]\n",
    "    )\n",
    "    ax.set_title(lot)\n",
    "\n",
    "for ax in axes:\n",
    "    for i, label in enumerate(ax.get_xticklabels()):\n",
    "        if i % 4 == 0:\n",
    "            label.set_rotation(90)\n",
    "        else:\n",
    "            label.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! We can see here most insights from both visualizations above.\n",
    "\n",
    "The weekly trends are vertical trends (green / red \"columns\"), and changes over time are horizontal trends, like complete rows (weeks) that are completely green, that demonstrate complete weeks with only `Free` statuses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Using Basic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, we need to choose the features we want, and handle their types.<br>\n",
    "Currently, the features we have look like that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_hourly_df = hourly_df.copy().reset_index()[['lot', 'datetime', 'class']]\n",
    "clean_hourly_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want the models to be able to use the inner information of `datetime`, we need to create columns describing the day and the time of the day.\n",
    "\n",
    "For day, the simplest option is a one-hot representation, with a column for every day of the week (using `pd.get_dummies`).<br>\n",
    "For hour, the simplest option is simply the numeric representation between 0-23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df = clean_hourly_df.copy()\n",
    "normalized_df['day'] = normalized_df['datetime'].dt.day_name()\n",
    "normalized_df['hour'] = normalized_df['datetime'].dt.hour\n",
    "normalized_df = normalized_df.set_index(['lot', 'datetime'])\n",
    "normalized_df = pd.get_dummies(normalized_df, prefix='', prefix_sep='')\n",
    "normalized_df = normalized_df.reset_index()\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When handling with a classification task, it is important to split wisely train and test data.\n",
    "\n",
    "Usually, in non-time-based problems, the best practice is to split the data randomly.<br>\n",
    "However, in our case, we want to simulate reality, in which we have prior data and we want to predict the future.\n",
    "\n",
    "For this reason, we start by splitting the data in a way that `train` is all data before 31/12/2020, and `test` is all the data from 2021. <br>\n",
    "\n",
    "In addition, we split our data by parking lot name, so we can train different models on each seperately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TEST_SPLIT_DATE = pd.to_datetime(date(year=2021, month=1, day=1)).tz_localize('Asia/Jerusalem')\n",
    "\n",
    "dataset_per_lot = {}\n",
    "for lot_name, lot_df in normalized_df.groupby('lot'):\n",
    "    train_data = lot_df[lot_df['datetime'] < TRAIN_TEST_SPLIT_DATE].drop(columns=['lot', 'datetime'])\n",
    "    test_data = lot_df[lot_df['datetime'] >= TRAIN_TEST_SPLIT_DATE].drop(columns=['lot', 'datetime'])\n",
    "    dataset_per_lot[lot_name] = (train_data, test_data)\n",
    "\n",
    "train_values = sum([len(x[0]) for x in dataset_per_lot.values()])\n",
    "test_values = sum([len(x[1]) for x in dataset_per_lot.values()])\n",
    "print(f'Train data has {train_values} values')\n",
    "print(f'Test data has {test_values} values')\n",
    "print(f'Test data is {100 * test_values / train_values:.2f}% of all data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def split_df_to_x_y(df): \n",
    "    df = df.copy()\n",
    "    return df, df.pop('class')\n",
    "\n",
    "scores = list()\n",
    "for lot, (train, test) in dataset_per_lot.items():\n",
    "    train_x, train_y = split_df_to_x_y(train)\n",
    "    test_x, test_y = split_df_to_x_y(test)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=RANDOM_STATE, max_iter=1e9)\n",
    "    clf.fit(train_x, train_y)\n",
    "    score = accuracy_score(y_true=test_y, y_pred=clf.predict(test_x))\n",
    "    scores.append({'lot':lot, 'score':score})\n",
    "\n",
    "scores_df = pd.DataFrame.from_dict(scores).set_index('lot')\n",
    "scores_df.loc['Average'] = scores_df['score'].mean()\n",
    "print(scores_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy results of this basic logistic regression are very diverse: the accuracy in Basel is as good as random (and worse than choosing the most common class) and the one in Dubnov is way higher than it's fair to expect.\n",
    "\n",
    "When you think about it, there are a few reasons for that, which are quite clear.<br>\n",
    "The first and main reason is that we chose a random point in time, and measured ourselves according to this data split only. This point in time is much too meaningfull - if we chose another point in time we would get completely different results.<br>\n",
    "The second reason is that we used less that 2/3 of the data for training, and it might have not been enough. We should use more data for training and test ourselves on less.<br>\n",
    "The third is related to the first and is specific to Dubnov. It seems that Dubnov lot was nearly only free during the whole year of 2021 so far, so a simple calssifier that always predicts \"free\" would have almost 100% accury. This is not True for all the time before 2021, though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better Data Split\n",
    "To avoid giving too much of a meaning to one chosen splitting point, we will use a technique similar to the classic k-folds cross validation.\n",
    "\n",
    "We will leave some of the data aside as the `test` set, and use all other data for training and validating the results.<br>\n",
    "The train-validation data will then be used in 10 different splits, each containing a 12-month period `train` set and a 1-month period `validation` set, of the month following the `train` year.\n",
    "\n",
    "Each model will be trained and tested 10 different times (independently), and its score will be the average accuracy score of all 10 times.<br>\n",
    "After comparing different models and different parameters, and choosing the best one according to its scores over the train-validation data, we will train the chosen model on all data before the `test` set starts, and evaluate its results on the `test` set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION = [\n",
    "    (7, 2020), (8, 2020), (9, 2020), (10, 2020), (11, 2020), (12, 2020), (1, 2021), (2, 2021), (3, 2021), (4, 2021)\n",
    "]\n",
    "TEST_SPLIT_MONTH_AND_YEAR = (5, 2021)\n",
    "\n",
    "def create_train_validation_test_datasets(df, print_results=False):\n",
    "    train_and_validation_datasets_per_lot = []\n",
    "    for month, year in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION:\n",
    "        current_dataset_per_lot = {}\n",
    "        for lot_name, lot_df in df.groupby('lot'):\n",
    "            starting_train_date = pd.to_datetime(date(year=year - 1, month=month, day=1)).tz_localize('Asia/Jerusalem')\n",
    "            starting_validation_date = pd.to_datetime(date(year=year, month=month, day=1)).tz_localize('Asia/Jerusalem')\n",
    "            if month == 12:\n",
    "                ending_validation_date = pd.to_datetime(date(year=year + 1, month=1, day=1)).tz_localize('Asia/Jerusalem')\n",
    "            else:\n",
    "                ending_validation_date = pd.to_datetime(date(year=year, month=month + 1, day=1)).tz_localize('Asia/Jerusalem')\n",
    "            train_data = lot_df[(lot_df['datetime'] >= starting_train_date) & (lot_df['datetime'] < starting_validation_date)]\n",
    "            validation_data = lot_df[(lot_df['datetime'] >= starting_validation_date) & (lot_df['datetime'] < ending_validation_date)]\n",
    "            current_dataset_per_lot[lot_name] = (\n",
    "                train_data.drop(columns=['lot', 'datetime']), validation_data.drop(columns=['lot', 'datetime'])\n",
    "            )\n",
    "        train_and_validation_datasets_per_lot.append(current_dataset_per_lot)\n",
    "\n",
    "    test_dataset_per_lot = {}\n",
    "    for lot_name, lot_df in df.groupby('lot'):\n",
    "        month, year = TEST_SPLIT_MONTH_AND_YEAR\n",
    "        starting_test_date = pd.to_datetime(date(year=year, month=month, day=1)).tz_localize('Asia/Jerusalem')\n",
    "        ending_test_date = pd.to_datetime(date(year=year, month=month + 1, day=1)).tz_localize('Asia/Jerusalem')\n",
    "        train_data = lot_df[lot_df['datetime'] < starting_test_date]\n",
    "        test_data = lot_df[(lot_df['datetime'] >= starting_test_date) & (lot_df['datetime'] < ending_test_date)]\n",
    "        test_dataset_per_lot[lot_name] = (\n",
    "            train_data.drop(columns=['lot', 'datetime']), test_data.drop(columns=['lot', 'datetime'])\n",
    "        )\n",
    "\n",
    "    if print_results:\n",
    "        print(f'Folds in train-validation data: {len(train_and_validation_datasets_per_lot)}')\n",
    "        print(f'Shape of example train data for validation: {train_and_validation_datasets_per_lot[0][\"Basel\"][0].shape}')\n",
    "        print(f'Shape of example validation data: {train_and_validation_datasets_per_lot[0][\"Basel\"][1].shape}')\n",
    "        print(f'\\nShape of example train data for test data: {test_dataset_per_lot[\"Basel\"][0].shape}')\n",
    "        print(f'Shape of example test data: {test_dataset_per_lot[\"Basel\"][1].shape}')\n",
    "    \n",
    "    return train_and_validation_datasets_per_lot, test_dataset_per_lot\n",
    "\n",
    "\n",
    "def _evaluate_model_once(model_training_func, model_evaluating_func, dataset_per_lot, use_test_as_val=False):\n",
    "    scores = {}\n",
    "    for lot, (train, test) in dataset_per_lot.items():\n",
    "        train_x, train_y = split_df_to_x_y(train)\n",
    "        test_x, test_y = split_df_to_x_y(test)\n",
    "        if use_test_as_val:\n",
    "            model = model_training_func(train_x, train_y, lot, val_x=test_x, val_y=test_y)\n",
    "        else:\n",
    "            model = model_training_func(train_x, train_y, lot)\n",
    "        score = model_evaluating_func(model, test_x, test_y)\n",
    "        scores[lot] = score\n",
    "    return scores\n",
    "\n",
    "def evaluate_model(model_training_func, model_evaluating_func, datasets_per_lot,\n",
    "                   print_results=True, detailed=False, row_names=None, use_test_as_val=False):\n",
    "    score_dicts = []\n",
    "    if print_results:\n",
    "        datasets_per_lot = tqdm(datasets_per_lot)\n",
    "    for dataset_per_lot in datasets_per_lot:\n",
    "        score_dicts.append(_evaluate_model_once(model_training_func, model_evaluating_func, dataset_per_lot, use_test_as_val=use_test_as_val))\n",
    "    lot_to_scores = {lot: [score_dict[lot] for score_dict in score_dicts] for lot in LOT_NAMES}\n",
    "    scores_df = pd.DataFrame.from_dict(lot_to_scores)\n",
    "    if row_names:\n",
    "        scores_df.index = row_names\n",
    "    if print_results and detailed:\n",
    "        scores_df['Average'] = scores_df.mean(axis=1)\n",
    "        scores_df.loc['Average'] = scores_df.mean()\n",
    "        plt.figure(figsize=(5,5))\n",
    "        sns.heatmap(scores_df, annot=True)\n",
    "        plt.show()\n",
    "    scores_df = scores_df.mean().T\n",
    "    scores_df.loc['Average'] = scores_df.mean()\n",
    "    if print_results:\n",
    "        print(scores_df.to_string())\n",
    "    return scores_df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(normalized_df,\n",
    "                                                                                                    print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we planned, a random fold has ~12 times more data in its `train` set than its `validation` one, and the final `test` set has similar amount of data to a typical `validation` set.\n",
    "\n",
    "Now let's run the same LogisticRegression model and see its average validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['average score'])\n",
    "score = evaluate_model(\n",
    "    model_training_func=lambda train_x, train_y, lot: (LogisticRegression(random_state=RANDOM_STATE, max_iter=1e9)\n",
    "                                                       .fit(train_x, train_y)),\n",
    "    model_evaluating_func=lambda model, test_x, test_y: accuracy_score(y_true=test_y, y_pred=model.predict(test_x)),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION]\n",
    ")\n",
    "results_df.loc['initial logistic regression'] = score['Average']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it makes much more sense!<br>\n",
    "For example, Basel's score is much higher than 50%, and Dubnov's is not 99.9% anymore.\n",
    "<br><br><br>\n",
    "Now that we have a good way to measure the models, let's try DecisionTree and RandomForest and compare them to the initial LogisticRegression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InitialDecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = evaluate_model(\n",
    "    model_training_func=lambda train_x, train_y, lot: (DecisionTreeClassifier(max_depth=4, random_state=RANDOM_STATE)\n",
    "                                                       .fit(train_x, train_y)),\n",
    "    model_evaluating_func=lambda model, test_x, test_y: accuracy_score(y_true=test_y, y_pred=model.predict(test_x)),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION]\n",
    ")\n",
    "results_df.loc['initial decision tree'] = score['Average']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example DecisionTree Decision Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "clf.fit(*split_df_to_x_y(train_and_validation_datasets_per_lot[0]['Basel'][0]))\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "_ = tree.plot_tree(\n",
    "    clf, \n",
    "    feature_names=[col for col in train_and_validation_datasets_per_lot[0]['Basel'][0].columns if col != 'class'],\n",
    "    proportion=True,\n",
    "    impurity=True,\n",
    "    filled=True,\n",
    "    fontsize=10,\n",
    "    class_names=['Full', 'Free']\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph describes the decision process of the example Decision Tree model.<br>Each node contains classifying criteria such as hour or day of the week. The root of the graph is the starting point and then we follow its classification rules down to the nodes. We go left when the critiera are met, and right if not.<br>\n",
    "For example, let's say we wan't to predict the status at Friday's evening (6pm). First node classifies by threshold hour<=17.5. Since our hour does not meet with this criterion, we take the right path. Then the criterion is Friday<=0.5 (\"not Friday\") so we go right again. Finally we reach the final leaf that tells us our predicted class is Free.<br>\n",
    "Each node contains extra information that tells us about the certainty of each decision node. Gini score implies the probability of a class to belong to multiple classes. A gini score of 0 means that the decision node is 100% sure there is only one single class. Samples is the percentage of trained data that reached the corresponding decision node. Value describes how the trained data is distributed among the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = evaluate_model(\n",
    "    model_training_func=lambda train_x, train_y, lot: (RandomForestClassifier(max_depth=4, n_estimators=10, random_state=RANDOM_STATE)\n",
    "                                                       .fit(train_x, train_y)),\n",
    "    model_evaluating_func=lambda model, test_x, test_y: accuracy_score(y_true=test_y, y_pred=model.predict(test_x)),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION]\n",
    ")\n",
    "results_df.loc['initial random forest'] = score['Average']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take it another step forward, and compare more models with more parameter combinations to find the best one for each lot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chossing the best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "all_clf_confs = [\n",
    "    (LogisticRegression, dict(max_iter=1e9, random_state=RANDOM_STATE)),\n",
    "    (DecisionTreeClassifier, dict(max_depth=4, random_state=RANDOM_STATE)),\n",
    "    (DecisionTreeClassifier, dict(max_depth=6, random_state=RANDOM_STATE)),\n",
    "    (DecisionTreeClassifier, dict(max_depth=8, random_state=RANDOM_STATE)),\n",
    "    (RandomForestClassifier, dict(max_depth=4, n_estimators=10, random_state=RANDOM_STATE)),\n",
    "    (RandomForestClassifier, dict(max_depth=6, n_estimators=10, random_state=RANDOM_STATE)),\n",
    "    (RandomForestClassifier, dict(max_depth=8, n_estimators=10, random_state=RANDOM_STATE)),\n",
    "    (KNeighborsClassifier, dict(n_neighbors=3)),\n",
    "    (KNeighborsClassifier, dict(n_neighbors=10)),\n",
    "    (KNeighborsClassifier, dict(n_neighbors=100)),\n",
    "    (AdaBoostClassifier, dict(random_state=RANDOM_STATE)),\n",
    "    (GaussianNB, dict()),\n",
    "]\n",
    "\n",
    "def find_lot_to_best_clf(clf_confs):\n",
    "    lot_to_max_score = {lot: -1 for lot in LOT_NAMES}\n",
    "    lot_to_best_clf = {lot: None for lot in LOT_NAMES}\n",
    "    for clf_class, clf_kwargs in tqdm(clf_confs, desc='Finding best classifier for each lot'):\n",
    "        lot_to_score = evaluate_model(\n",
    "            model_training_func=lambda train_x, train_y, lot: clf_class(**clf_kwargs).fit(train_x, train_y),\n",
    "            model_evaluating_func=lambda model, test_x, test_y: accuracy_score(y_true=test_y, y_pred=model.predict(test_x)),\n",
    "            datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "            print_results=False\n",
    "        )\n",
    "        for lot in LOT_NAMES:\n",
    "            if lot_to_score[lot] > lot_to_max_score[lot]:\n",
    "                lot_to_max_score[lot] = lot_to_score[lot]\n",
    "                lot_to_best_clf[lot] = (clf_class, clf_kwargs)\n",
    "    return lot_to_best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lot_to_best_clf = find_lot_to_best_clf(all_clf_confs)\n",
    "\n",
    "for lot, (cls, kwargs) in lot_to_best_clf.items():\n",
    "    params = {k: v for k, v in kwargs.items() if k != 'random_state'}\n",
    "    print(f'{lot}:{\" \" * (15 - len(lot))}{cls.__name__}{\" \" * (30 - len(cls.__name__))}(params: {params})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the results show, the best classifiers is not absolute and every lot has its best configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = evaluate_model(\n",
    "    model_training_func=lambda train_x, train_y, lot: lot_to_best_clf[lot][0](**lot_to_best_clf[lot][1]).fit(train_x, train_y),\n",
    "    model_evaluating_func=lambda model, test_x, test_y: accuracy_score(y_true=test_y, y_pred=model.predict(test_x)),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION]\n",
    ")\n",
    "results_df.loc['initial best classifier'] = score['Average']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This score is amazing, comparing to the initial logistic regression we started with. By changing nothing but models and params, the accuracy score was improved by almost 8%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Time Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first improvement we want to try is to change the representation of the hour and the day from a numeric value of 0-23 and a one-hot representation, to a continuous representation in which the difference between the hours 23 and 1 is the same as the difference between 1 and 3, and the same with days of the week.<br>\n",
    "To do so, we will create a sinus and a cosinus of the day and the week, and instead of saving the hour or the day, we will save a point on the wave that represents the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SECONDS_IN_DAY = 60 * 60 * 24\n",
    "SECONDS_IN_WEEK = SECONDS_IN_DAY * 7\n",
    "\n",
    "sin_normalized_df = clean_hourly_df.copy()\n",
    "ts = sin_normalized_df['datetime'].astype('int64') // 10**9\n",
    "sin_normalized_df['day sin'] = np.sin(ts * (2 * np.pi / SECONDS_IN_DAY))\n",
    "sin_normalized_df['day cos'] = np.cos(ts * (2 * np.pi / SECONDS_IN_DAY))\n",
    "sin_normalized_df['week sin'] = np.sin(ts * (2 * np.pi / SECONDS_IN_WEEK))\n",
    "sin_normalized_df['week cos'] = np.cos(ts * (2 * np.pi / SECONDS_IN_WEEK))\n",
    "display(sin_normalized_df)\n",
    "\n",
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(sin_normalized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lot_to_best_clf = find_lot_to_best_clf(all_clf_confs)\n",
    "score = evaluate_model(\n",
    "    model_training_func=lambda train_x, train_y, lot: lot_to_best_clf[lot][0](**lot_to_best_clf[lot][1]).fit(train_x, train_y),\n",
    "    model_evaluating_func=lambda model, test_x, test_y: accuracy_score(y_true=test_y, y_pred=model.predict(test_x)),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION]\n",
    ")\n",
    "results_df.loc['advanced time norm best classifier'] = score['Average']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are surprising - the accuracy with the original representation of the days and hours led to higher accuracy.\n",
    "So, we will go back to using the original representation for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding More Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to enhance our results, we want to add as much relevant information as possible to the dataset.<br>\n",
    "We will use the following data:\n",
    "- Weather\n",
    "- Day / night hours\n",
    "- Holidays\n",
    "\n",
    "All the data was taken from the internet using some good search and crawling methods that won't be detailed here, and saved to different CSV files.\n",
    "\n",
    "We are going to use each of the files separately, find its impact, and in the end, merge everything together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weather_df = pd.read_csv('weather.csv')\n",
    "initial_weather_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weather_df['Conditions'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weather dataset includes a lot of information, most of it seems irrelevant or duplicated.\n",
    "Our gut feeling was that rain would have a high impact on parking ratio, and maybe temperature as well, as people change habbits in different weather conditions, for example, go to the beach (and park near it) more as the weather is hotter.\n",
    "\n",
    "To explore the data, let's first merge it with our main dataframe and look for correlations with `class` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weather_df['hour_datetime'] = (\n",
    "    initial_weather_df['Date time']\n",
    "    .apply(lambda d: datetime.strptime(d, '%m/%d/%Y %H:%M:%S'))\n",
    "    .dt.tz_localize('Asia/Jerusalem', 'infer')\n",
    ")\n",
    "initial_weather_df['Conditions'] = initial_weather_df['Conditions'].map({\n",
    "    'Partially cloudy': 'Partially cloudy',\n",
    "    'Clear': 'Clear',\n",
    "    'Rain, Partially cloudy': 'Rain',\n",
    "    'Rain, Overcast': 'Rain',\n",
    "    'Rain': 'Rain',\n",
    "})\n",
    "weather_research_df = normalized_df.copy()\n",
    "weather_research_df['hour_datetime'] = weather_research_df['datetime'].copy().dt.floor('H', ambiguous=True)\n",
    "weather_research_df = (\n",
    "    weather_research_df\n",
    "    .merge(initial_weather_df, on='hour_datetime', how='left')\n",
    "    .drop(columns=['hour_datetime'])\n",
    ")\n",
    "weather_research_df = pd.get_dummies(weather_research_df, columns=['Conditions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_corr_df = pd.DataFrame(weather_research_df.corr()['class'].sort_values(key=abs, ascending=False))\n",
    "weather_corr_df = weather_corr_df.reset_index()\n",
    "weather_corr_df = weather_corr_df.rename(columns={'index': 'column', 'class': 'corr with class'})\n",
    "weather_corr_df['non none ratio'] = weather_corr_df['column'].apply(lambda col: (\n",
    "    len(weather_research_df[~weather_research_df[col].isna()]) / len(weather_research_df)\n",
    "))\n",
    "with pd.option_context(\"display.max_rows\", 50):\n",
    "    display(weather_corr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are surprising! `Heat Index` and `Cloud Cover` are more correlated to `class` than `Conditions_Rain`!\n",
    "The next step is to actually use the data to enhance the classification. In order to do that, we will choose some of the features. We will use only features that have a decent correlation, a decent existance ratio, and make at least some sense to us (as oppose to `Wind Direction`, which simply does not).<br>\n",
    "Therefore we will only take the features `Heat Index`, `Cloud Cover` and `Conditions`.\n",
    "Temperature has such a low correlation that it will not be included!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weather_df[['Heat Index', 'Cloud Cover']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get rid of `None`s, we will fill none values with the minimum value of each of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = normalized_df.copy()\n",
    "weather_df['hour_datetime'] = weather_df['datetime'].copy().dt.floor('H', ambiguous=True)\n",
    "weather_df = (\n",
    "    weather_df\n",
    "    .merge(initial_weather_df[['hour_datetime', 'Heat Index', 'Cloud Cover', 'Conditions']], on='hour_datetime', how='left')\n",
    "    .drop(columns=['hour_datetime'])\n",
    ")\n",
    "weather_df['Heat Index'] = weather_df['Heat Index'].fillna(weather_df['Heat Index'].min())\n",
    "weather_df['Cloud Cover'] = weather_df['Cloud Cover'].fillna(weather_df['Cloud Cover'].min())\n",
    "weather_df = pd.get_dummies(weather_df, columns=['Conditions'], prefix='', prefix_sep='')\n",
    "display(weather_df)\n",
    "\n",
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lot_to_best_clf = find_lot_to_best_clf(all_clf_confs)\n",
    "score = evaluate_model(\n",
    "    model_training_func=lambda train_x, train_y, lot: lot_to_best_clf[lot][0](**lot_to_best_clf[lot][1]).fit(train_x, train_y),\n",
    "    model_evaluating_func=lambda model, test_x, test_y: accuracy_score(y_true=test_y, y_pred=model.predict(test_x)),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot\n",
    ")\n",
    "results_df.loc['weather best classifier'] = score['Average']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go! The accuracy is improved by ~0.1% thanks to the new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day / night hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_sun_hours_df = pd.read_csv('sun_hours.csv')\n",
    "initial_sun_hours_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The day / night dataset includes the sunrise and sunset exact minute for each day.\n",
    "Our initial expectation was that it would have a high correlation with our `class`, because people change habbits according to the daylight hours, especially in the evening (i.e. we expect `sunset` to be more informative than `sunrise`).\n",
    "\n",
    "To be able to use the data, let's normalize it, merge with our main dataframe and check its correlation with `class`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_sun_hours_df['sunrise'] = initial_sun_hours_df['sunrise'].str.split(':').apply(lambda tup: int(tup[0]) * 24 + int(tup[1]))\n",
    "initial_sun_hours_df['sunset'] = initial_sun_hours_df['sunset'].str.split(':').apply(lambda tup: int(tup[0]) * 24 + int(tup[1]))\n",
    "initial_sun_hours_df['sunrise'] = (initial_sun_hours_df['sunrise'] - initial_sun_hours_df['sunrise'].mean()) / (initial_sun_hours_df['sunrise'].max() - initial_sun_hours_df['sunrise'].min())\n",
    "initial_sun_hours_df['sunset'] = (initial_sun_hours_df['sunset'] - initial_sun_hours_df['sunset'].mean()) / (initial_sun_hours_df['sunset'].max() - initial_sun_hours_df['sunset'].min())\n",
    "initial_sun_hours_df['date'] = initial_sun_hours_df['date'].astype('datetime64[ns]')\n",
    "initial_sun_hours_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_hours_df = normalized_df.copy()\n",
    "sun_hours_df['date'] = sun_hours_df['datetime'].dt.date.astype('datetime64[ns]')\n",
    "sun_hours_df = (\n",
    "    sun_hours_df\n",
    "    .merge(initial_sun_hours_df, on='date', how='left')\n",
    "    .drop(columns=['date'])\n",
    ")\n",
    "\n",
    "print(sun_hours_df.corr('spearman')['class'].sort_values(key=abs, ascending=False).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, `sunrise` is the one that has a much higher correlation than sunset.\n",
    "Let's see how it helps our classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(sun_hours_df.drop(columns=['sunset']))\n",
    "lot_to_best_clf = find_lot_to_best_clf(all_clf_confs)\n",
    "score = evaluate_model(\n",
    "    model_training_func=lambda train_x, train_y, lot: lot_to_best_clf[lot][0](**lot_to_best_clf[lot][1]).fit(train_x, train_y),\n",
    "    model_evaluating_func=lambda model, test_x, test_y: accuracy_score(y_true=test_y, y_pred=model.predict(test_x)),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot\n",
    ")\n",
    "results_df.loc['day night best classifier'] = score['Average']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that this new information only confuses the classifiers.\n",
    "Let's double check that adding sunset back doesn't help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(sun_hours_df)\n",
    "lot_to_best_clf = find_lot_to_best_clf(all_clf_confs)\n",
    "_ = evaluate_model(\n",
    "    model_training_func=lambda train_x, train_y, lot: lot_to_best_clf[lot][0](**lot_to_best_clf[lot][1]).fit(train_x, train_y),\n",
    "    model_evaluating_func=lambda model, test_x, test_y: accuracy_score(y_true=test_y, y_pred=model.predict(test_x)),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we made the right decision leaving sunset out, but anyway, the new data does not help.\n",
    "We will leave it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_holiday_df = pd.read_csv('holidays.csv')\n",
    "initial_holiday_df['date'] = initial_holiday_df.apply(lambda row: pd.Timestamp(date(year=row['year'], month=datetime.strptime(row['month'], '%b').month, day=row['day'])), axis=1)\n",
    "initial_holiday_df = initial_holiday_df[['date', 'holiday_name', 'holiday_class']]\n",
    "initial_holiday_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have here is a list of all holidays in the relevant dates, including a large range of what can be called holidays:\n",
    "- `no_vaction` - days that are special but don't make most people change their routines (e.g. Tisha B'Av, Tu Bishvat)\n",
    "- `mainly_school_vacation` - days that are special and make some people change their routines, especially children (e.g. Hanukkah, Purim)\n",
    "- `erev_hag` - days that their morning is a vacation for some people and the evening is for most people (e.g. Erev Rosh HaShana)\n",
    "- `hol_hamoed` - days that are vacations for some people (e.g. Passover (Day 4))\n",
    "- `all_vacation` - days that are vacations for almost everybody (e.g. Rosh HaShana)\n",
    "- `elections` - days that are supposed to happen once in four years and happened four times in our two years of data\n",
    "\n",
    "Let's merge the dataframe with our main one and see how the `class` changes during different holidays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_df = normalized_df.copy()\n",
    "holiday_df['date'] = holiday_df['datetime'].dt.date.astype('datetime64[ns]')\n",
    "holiday_df = (\n",
    "    holiday_df\n",
    "    .merge(initial_holiday_df, on='date', how='left')\n",
    "    .drop(columns=['date', 'holiday_name'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "\n",
    "_ = sns.histplot(\n",
    "    data=holiday_df[~holiday_df['holiday_class'].isna()],\n",
    "    x='holiday_class',\n",
    "    hue='class',\n",
    "    multiple='dodge',\n",
    "    palette=GREEN_RED_PALETTE,\n",
    "    shrink=0.7,\n",
    ").set_title('Class Distribution Per Parking Lot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Super interesting! It looks very indicative - `erev_hag` is mainly free, `all_vacation` and `hol_hamoed` are similar but a bit less, and `elections` are mainly full which is very unusual.\n",
    "\n",
    "Let's validate our conclusions with correlation scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_df['holiday_class'] = holiday_df['holiday_class'].fillna('no_holiday')\n",
    "holiday_df = holiday_df.set_index(['lot', 'datetime'])\n",
    "holiday_df = pd.get_dummies(holiday_df)\n",
    "holiday_df = holiday_df.reset_index()\n",
    "\n",
    "print(holiday_df.corr()['class'].sort_values(key=abs, ascending=False).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, the results show what we expected and we are ready to use it in our classification.\n",
    "\n",
    "Let's get rid of the non-correlated ones and continue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_df = holiday_df.drop(columns=['holiday_class_mainly_school_vacation', 'holiday_class_no_vacation'])\n",
    "\n",
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(holiday_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lot_to_best_clf = find_lot_to_best_clf(all_clf_confs)\n",
    "score = evaluate_model(\n",
    "    model_training_func=lambda train_x, train_y, lot: lot_to_best_clf[lot][0](**lot_to_best_clf[lot][1]).fit(train_x, train_y),\n",
    "    model_evaluating_func=lambda model, test_x, test_y: accuracy_score(y_true=test_y, y_pred=model.predict(test_x)),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot\n",
    ")\n",
    "results_df.loc['holidays best classifier'] = score['Average']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the data did help the results. Not as much as we expected, but any accuracy increase is good news.\n",
    "\n",
    "The next step is, obviously, merging the good from each dataset together and see the results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_df = holiday_df.copy().merge(weather_df, on=[\n",
    "    'lot', 'datetime', 'class', 'hour',\n",
    "    'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'\n",
    "])\n",
    "display(enriched_df)\n",
    "\n",
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(enriched_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lot_to_best_clf = find_lot_to_best_clf(all_clf_confs)\n",
    "score = evaluate_model(\n",
    "    model_training_func=lambda train_x, train_y, lot: lot_to_best_clf[lot][0](**lot_to_best_clf[lot][1]).fit(train_x, train_y),\n",
    "    model_evaluating_func=lambda model, test_x, test_y: accuracy_score(y_true=test_y, y_pred=model.predict(test_x)),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION]\n",
    ")\n",
    "results_df.loc['merged data best classifier'] = score['Average']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final result is certainly higher than the \"initial best classifier\"!\n",
    "\n",
    "We are now ready to test our final classifier on the `test` data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df = pd.DataFrame(columns=['average score'])\n",
    "lot_to_best_clf = find_lot_to_best_clf(all_clf_confs)\n",
    "score = evaluate_model(\n",
    "    model_training_func=lambda train_x, train_y, lot: lot_to_best_clf[lot][0](**lot_to_best_clf[lot][1]).fit(train_x, train_y),\n",
    "    model_evaluating_func=lambda model, test_x, test_y: accuracy_score(y_true=test_y, y_pred=model.predict(test_x)),\n",
    "    datasets_per_lot=[test_dataset_per_lot]\n",
    ")\n",
    "test_results_df.loc['sklearn best classifiers'] = score['Average']\n",
    "\n",
    "test_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are amazing. Not only is the average score pretty high, but it is also very consistent with our validation results, which means we didn't overfit the training and validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "Let's utilize keras deep learning models to improve our prediction accuracy!\n",
    "\n",
    "## Classification with Deep Learning\n",
    "Before trying some fancy deep learning models, we should start with a simple DNN that attempts to predict parking availability status by our time features (sin/cos of day/week)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def _model_training_func(train_x, train_y, lot, model_creation_func, epochs=10, patience=2, \n",
    "                         loss_function=tf.losses.MeanSquaredError, metrics_function=tf.keras.metrics.BinaryAccuracy, \n",
    "                         optimizer_function=tf.optimizers.Adam):\n",
    "    model = model_creation_func()\n",
    "    train_x = np.array(train_x, dtype=np.float32)\n",
    "    train_y = np.array(train_y, dtype=np.float32)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=patience, mode='min')\n",
    "    model.compile(loss=loss_function(), \n",
    "                  optimizer=optimizer_function(),\n",
    "                  metrics=[metrics_function()])\n",
    "    model.fit(train_x, train_y, epochs=epochs, verbose=0, callbacks=[early_stopping])\n",
    "    return model\n",
    "    \n",
    "def _model_evaluating_func(model, test_x, test_y):\n",
    "    test_x = np.array(test_x, dtype=np.float32)\n",
    "    test_y = np.array(test_y, dtype=np.float32)\n",
    "    return model.evaluate(test_x, test_y, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear DNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(sin_normalized_df)\n",
    "\n",
    "def _create_simple_clsf_model():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=1)\n",
    "    ])\n",
    "\n",
    "score = evaluate_model(\n",
    "    model_training_func=partial(_model_training_func, model_creation_func=_create_simple_clsf_model),\n",
    "    model_evaluating_func=_model_evaluating_func,\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we got decent prediction accuracy with the linear model. We might get better results if we add a hidden layer.\n",
    "#### Dense DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_dense_clsf_model():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=1)\n",
    "    ])\n",
    "\n",
    "score = evaluate_model(\n",
    "    model_training_func=partial(_model_training_func, model_creation_func=_create_dense_clsf_model),\n",
    "    model_evaluating_func=_model_evaluating_func,\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got some really nice results! Let's see what happens when we add more hidden layers with dropout to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_dense2_clsf_model():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=32),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.Dropout(0.01),\n",
    "        tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=1)\n",
    "    ])\n",
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(sin_normalized_df)\n",
    "\n",
    "\n",
    "score = evaluate_model(\n",
    "    model_training_func=partial(_model_training_func, model_creation_func=_create_dense2_clsf_model),\n",
    "    model_evaluating_func=_model_evaluating_func,\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION]\n",
    ")\n",
    "results_df.loc['keras simple dense classifier'] = score['Average']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more and more layer not necessarily improved accuracy. Some lots improved while other didn't. \n",
    "Let's try to add more features to the model, like we did before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_enriched_df = (sin_normalized_df\n",
    "                   .merge(enriched_df, on=[\"datetime\", \"lot\", \"class\"])\n",
    "                   .drop(columns=['hour', 'Friday', 'Monday', 'Saturday', 'Sunday','Thursday', 'Tuesday', 'Wednesday'])\n",
    "                   .copy())\n",
    "\n",
    "def _create_dense3_clsf_model():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=4, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=1)\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(sin_enriched_df)\n",
    "\n",
    "score = evaluate_model(\n",
    "    model_training_func=partial(_model_training_func, model_creation_func=_create_dense3_clsf_model, epochs=20, patience=5),\n",
    "    model_evaluating_func=_model_evaluating_func,\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION]\n",
    ")\n",
    "results_df.loc['keras enriched dense classifier'] = score['Average']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, it seems like adding more features confused our model. Lots like Basel and Asuta are usually not affected by weather or vacations and we got less accurate predictions there. On the other hand, seasonal lots located near attractions such as Sheraton, Dan and Habima got a better prediction.<br>\n",
    "Let's evaluate our best model on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(sin_normalized_df)\n",
    "\n",
    "\n",
    "score = evaluate_model(\n",
    "    model_training_func=partial(_model_training_func, model_creation_func=_create_dense2_clsf_model),\n",
    "    model_evaluating_func=_model_evaluating_func,\n",
    "    datasets_per_lot=[test_dataset_per_lot],\n",
    ")\n",
    "test_results_df.loc['keras simple dense classifier'] = score['Average']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series forcasting with DNN\n",
    "So far we only classified data based on their features without the context of their timely order.<br>\n",
    "In the next section, we will create models that forecasts new timesteps based on prior information.<br>\n",
    "The model's input will be `[input_timesteps, labels+features]` and output would be `[output_timesteps, labels]`.<br>\n",
    "For example, a model that forecasts 3 hours into to future based on 6 hours with 4 labels (sin/cos of day/week) and 1 feature (class) would have input shape of `[6, 5]` and output shape of `[3, 1]`.<br>\n",
    "To build such dataset, we will use `tf.keras.preprocessing.timeseries_dataset_from_array` that breaks the dataset into batches of consecutive timeseries with predefined lengths. Then we will split the input from the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_dataset(df_x, df_y, input_timesteps, output_timesteps, \n",
    "                      y_labels_slice=slice(-1, None), add_y_features_to_x=False):\n",
    "    # df_x and df_y split is irrelevant and we need to rebuild it\n",
    "    df = df_x.copy()\n",
    "    df['class'] = df_y\n",
    "    \n",
    "    # normalize dataframe types\n",
    "    data_arr = np.array(df, dtype=np.float32)\n",
    "    \n",
    "    # create timeseries dataset\n",
    "    ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "        data_arr,\n",
    "        targets=None,\n",
    "        sequence_stride=1,\n",
    "        sequence_length=input_timesteps + output_timesteps, \n",
    "        shuffle=True,\n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    def _split_x_y(batch):\n",
    "        x = batch[:, :input_timesteps, :]\n",
    "        y = batch[:, input_timesteps:, y_labels_slice]\n",
    "        \n",
    "        if add_y_features_to_x and input_timesteps == output_timesteps:\n",
    "            y_vec = tf.unstack(batch[:, input_timesteps:, :], axis=2)\n",
    "            del y_vec[y_labels_slice]\n",
    "            y_features = tf.stack(y_vec, axis=2)\n",
    "            x = tf.concat([x, y_features], axis=2)  \n",
    "        \n",
    "        # set shapes for clarity\n",
    "        x.set_shape([None, input_timesteps, None])\n",
    "        y.set_shape([None, output_timesteps, None])\n",
    "        return x, y\n",
    "    \n",
    "    ds = ds.map(_split_x_y)\n",
    "    \n",
    "    return ds\n",
    "    \n",
    "def _ts_model_training_func(train_x, train_y, lot, model_creation_func, epochs=10, patience=2, input_timesteps=1, output_timesteps=1, fit_model=True, \n",
    "                            loss_function=tf.losses.MeanSquaredError, metrics_function=tf.keras.metrics.BinaryAccuracy, \n",
    "                            optimizer_function=tf.optimizers.Adam, y_labels_slice=slice(-1, None),\n",
    "                            val_x=None, val_y=None, add_y_features_to_x=False):\n",
    "    model = model_creation_func()\n",
    "    dataset = _generate_dataset(train_x, train_y, input_timesteps, output_timesteps, y_labels_slice=y_labels_slice, add_y_features_to_x=add_y_features_to_x)\n",
    "    callbacks = []\n",
    "    dataset_val = None\n",
    "    if val_x is not None:\n",
    "        dataset_val = _generate_dataset(val_x, val_y, \n",
    "                                        input_timesteps, output_timesteps, \n",
    "                                        y_labels_slice=y_labels_slice, add_y_features_to_x=add_y_features_to_x)\n",
    "        callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='min')]\n",
    "    model.compile(loss=loss_function(), \n",
    "                  optimizer=optimizer_function(),\n",
    "                  metrics=[metrics_function()])\n",
    "    if fit_model:\n",
    "        model.fit(dataset, epochs=epochs, verbose=0, validation_data=dataset_val)\n",
    "    return model\n",
    "    \n",
    "def _ts_model_evaluating_func(model, test_x, test_y, \n",
    "                              input_timesteps=1, output_timesteps=1, \n",
    "                              y_labels_slice=slice(-1, None), add_y_features_to_x=False):\n",
    "    dataset = _generate_dataset(test_x, test_y, \n",
    "                                input_timesteps, output_timesteps, \n",
    "                                y_labels_slice=y_labels_slice, add_y_features_to_x=add_y_features_to_x)\n",
    "    return model.evaluate(dataset, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Step prediction\n",
    "Let's start by predicting a data point just like before, but this the model will have access to previous hours.\n",
    "\n",
    "#### Baseline Repeat\n",
    "Before we create deep learning models, let's create a benchmark with a simple models that repeats over and over the input variables out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineRepeat(tf.keras.Model):\n",
    "    def __init__(self, output_timesteps=None):\n",
    "        super().__init__()\n",
    "        self._output_timesteps = output_timesteps\n",
    "        \n",
    "    def call(self, inputs):\n",
    "#         return inputs[:, :, -1:]\n",
    "        # inputs is a tensor with shape [batch, timesteps, features]\n",
    "        input_timesteps = inputs.shape[1]\n",
    "        output_timesteps = self._output_timesteps or input_timesteps\n",
    "        \n",
    "        multiplier = (output_timesteps // input_timesteps) + 1\n",
    "        \n",
    "        outputs = tf.concat([inputs]*multiplier, axis=1)[:, :output_timesteps, -1:]\n",
    "        return outputs\n",
    "    \n",
    "def _create_baseline_repeat(output_timesteps=None):\n",
    "    return BaselineRepeat(output_timesteps)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's run the repeat baseline with 1 hour prediction. Model gets features and label of one hour and predicts the label of the next hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(sin_normalized_df)\n",
    "\n",
    "\n",
    "score = evaluate_model(\n",
    "    model_training_func=partial(_ts_model_training_func, model_creation_func=_create_baseline_repeat, input_timesteps=1 ,output_timesteps=1, fit_model=False),\n",
    "    model_evaluating_func=partial(_ts_model_evaluating_func, output_timesteps=1),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION]\n",
    ")\n",
    "results_df.loc['keras 1h prediction baseline'] = score['Average']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! we got really nice results here. Let's see if we can push this further using deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_ts_model = None\n",
    "def create_linear_ts_model():\n",
    "    global linear_ts_model\n",
    "    linear_ts_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=1)\n",
    "    ])\n",
    "    return linear_ts_model\n",
    "\n",
    "score = evaluate_model(\n",
    "    model_training_func=partial(_ts_model_training_func, \n",
    "                                model_creation_func=create_linear_ts_model, \n",
    "                                input_timesteps=1, output_timesteps=1,\n",
    "                                add_y_features_to_x=True\n",
    "                                ),\n",
    "    model_evaluating_func=partial(_ts_model_evaluating_func, \n",
    "                                  input_timesteps=1, output_timesteps=1, \n",
    "                                  add_y_features_to_x=True),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION],\n",
    "    use_test_as_val=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats's interesting, the simple dnn model could not beat the baseline model. Our model found a local optima that was not good enough. Let's dig into our model and see what it learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_ts_model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the most significant feature used for prediction was the last hour's label (class).<br>\n",
    "Let's see what happens when we use different optimizer such as SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = evaluate_model(\n",
    "    model_training_func=partial(_ts_model_training_func, \n",
    "                                model_creation_func=create_linear_ts_model, \n",
    "                                input_timesteps=1 ,output_timesteps=1,\n",
    "                                optimizer_function=tf.keras.optimizers.SGD,\n",
    "                                add_y_features_to_x=True\n",
    "                               ),\n",
    "    model_evaluating_func=partial(_ts_model_evaluating_func, \n",
    "                                  input_timesteps=1, output_timesteps=1, \n",
    "                                  add_y_features_to_x=True),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION],\n",
    "    use_test_as_val=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_ts_model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the model scored virtually the same as our baseline. When picking into its weights, we can see it gave the class feature more significance.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try again with another hidden layer and activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_ts_model = None\n",
    "def create_dense_ts_model():\n",
    "    global dense_ts_model\n",
    "    dense_ts_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=1)\n",
    "    ])\n",
    "    return dense_ts_model\n",
    "\n",
    "score = evaluate_model(\n",
    "    model_training_func=partial(_ts_model_training_func, \n",
    "                                model_creation_func=create_dense_ts_model, \n",
    "                                input_timesteps=1, output_timesteps=1,\n",
    "                                add_y_features_to_x=True\n",
    "                                ),\n",
    "    model_evaluating_func=partial(_ts_model_evaluating_func, \n",
    "                                  input_timesteps=1, output_timesteps=1, \n",
    "                                  add_y_features_to_x=True),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION],\n",
    "    use_test_as_val=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly the same results as baseline.\n",
    "### Multistep forecast\n",
    "Next, we will attempt to predict multiple points instead of single prediction. \n",
    "#### Baseline\n",
    "Let's see how well our baseline scores when it needs to predict a whole day based on its previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(sin_normalized_df)\n",
    "\n",
    "\n",
    "score = evaluate_model(\n",
    "    model_training_func=partial(_ts_model_training_func, \n",
    "                                model_creation_func=_create_baseline_repeat, \n",
    "                                input_timesteps=24 ,output_timesteps=24, fit_model=False),\n",
    "    model_evaluating_func=partial(_ts_model_evaluating_func, \n",
    "                                  input_timesteps=24, output_timesteps=24),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION]\n",
    ")\n",
    "results_df.loc['keras 24h prediction baseline'] = score['Average']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model reached 82% accuracy! Like before, let's try to improve accuracy using deep learning models.\n",
    "#### Simple DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = evaluate_model(\n",
    "    model_training_func=partial(_ts_model_training_func, \n",
    "                                model_creation_func=create_dense_ts_model, \n",
    "                                input_timesteps=24, output_timesteps=24,\n",
    "                                optimizer_function=tf.keras.optimizers.SGD, epochs=20,\n",
    "                                add_y_features_to_x=True\n",
    "                               ),\n",
    "    model_evaluating_func=partial(_ts_model_evaluating_func, \n",
    "                                  input_timesteps=24, output_timesteps=24, \n",
    "                                  add_y_features_to_x=True),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION],\n",
    "    use_test_as_val=True\n",
    ")\n",
    "results_df.loc['keras 24h prediction dense'] = score['Average']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great! Even though our model is still pretty basic, we scored with pretty decent accuracy!\n",
    "#### CNN Model\n",
    "Next, we will try to improve accuracy by granting our model access to multiple timesteps features each time. <br>\n",
    "The input of our model is a 3d tensor with shape of`batch, timestep, features`. Dense layers operate only on the 3rd axis, so different timesteps are tuned separately.<br>\n",
    "We can use `Flatten` or `Conv1D` layers to operate on multiple timesteps simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ts_conv_model():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(24)),\n",
    "        tf.keras.layers.Dense(24, kernel_initializer=tf.initializers.zeros()),\n",
    "        tf.keras.layers.Reshape([24, 1]),\n",
    "    ])\n",
    "\n",
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(sin_normalized_df)\n",
    "\n",
    "score = evaluate_model(\n",
    "    model_training_func=partial(_ts_model_training_func, \n",
    "                                model_creation_func=create_ts_conv_model, \n",
    "                                input_timesteps=24, output_timesteps=24,\n",
    "                                optimizer_function=tf.keras.optimizers.SGD, epochs=20,\n",
    "                                add_y_features_to_x=True\n",
    "                               ),\n",
    "    model_evaluating_func=partial(_ts_model_evaluating_func, \n",
    "                                  input_timesteps=24, output_timesteps=24, \n",
    "                                  add_y_features_to_x=True),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION],\n",
    "    use_test_as_val=True\n",
    ")\n",
    "results_df.loc['keras 24h prediction cnn'] = score['Average']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding CNN layer did not improve our accuracy at all. Let's try another approach and use LSTM layer that learns \"trends\" with fewer trainable variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ts_lstm_model():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "        tf.keras.layers.Dense(24, kernel_initializer=tf.initializers.zeros()),\n",
    "        tf.keras.layers.Reshape([24, 1]),\n",
    "    ])\n",
    "\n",
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(sin_normalized_df)\n",
    "\n",
    "score = evaluate_model(\n",
    "    model_training_func=partial(_ts_model_training_func, \n",
    "                                model_creation_func=create_ts_lstm_model, \n",
    "                                input_timesteps=24, output_timesteps=24,\n",
    "                                optimizer_function=tf.keras.optimizers.SGD, epochs=20,\n",
    "                                add_y_features_to_x=True\n",
    "                               ),\n",
    "    model_evaluating_func=partial(_ts_model_evaluating_func, \n",
    "                                  input_timesteps=24, output_timesteps=24, \n",
    "                                  add_y_features_to_x=True),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION],\n",
    "    use_test_as_val=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not improving. The LSTM layer could hide the y features (sin/cos of day/week) we injected into our dataset. To overcome this issue, we can come up with non-sequential model that feeds the following Dense layer with the original y features input.<br>\n",
    "To do so, we will create a custom class that derives from keras Model, and write our logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmWithYFeatures(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = tf.keras.layers.LSTM(32, return_sequences=False)\n",
    "        self.dense = tf.keras.layers.Dense(32, activation='relu')\n",
    "        self.dense_output = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        # extract only x-features\n",
    "        x = inputs[:, :, :5]\n",
    "        y_features = inputs[:, :, 5:]\n",
    "        \n",
    "        # (batch, steps, x_features) => (batch, lstm_units)\n",
    "        lstm_units = self.lstm(x)\n",
    "        \n",
    "        # (batch, lstm_units) => (batch, 1, lstm_units)\n",
    "        lstm_units = lstm_units[:, tf.newaxis, :]\n",
    "        \n",
    "        # (batch, 1, lstm_units) => (batch, steps, lstm_units)\n",
    "        lstm_units = tf.concat([lstm_units]*24, axis=1)\n",
    "        \n",
    "        # (batch, steps, lstm_units) => (batch, steps, lstm_unit+y_features)\n",
    "        lstm_with_y_features = tf.concat([lstm_units, y_features], axis=2)\n",
    "        \n",
    "        # (batch, steps, lstm_unit+y_features) => (batch, steps, dense_units)\n",
    "        predictions = self.dense(lstm_with_y_features)\n",
    "        \n",
    "        # (batch, steps, dense_units) => (batch, steps, y_label)\n",
    "        predictions = self.dense_output(predictions)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm2_model():\n",
    "    return LstmWithYFeatures()\n",
    "\n",
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(sin_normalized_df)\n",
    "\n",
    "score = evaluate_model(\n",
    "    model_training_func=partial(_ts_model_training_func, \n",
    "                                model_creation_func=create_lstm2_model, \n",
    "                                input_timesteps=24, output_timesteps=24,\n",
    "                                optimizer_function=tf.keras.optimizers.SGD, epochs=20,\n",
    "                                add_y_features_to_x=True\n",
    "                               ),\n",
    "    model_evaluating_func=partial(_ts_model_evaluating_func, \n",
    "                                  input_timesteps=24, output_timesteps=24, \n",
    "                                  add_y_features_to_x=True),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION],\n",
    "    use_test_as_val=True\n",
    ")\n",
    "results_df.loc['keras 24h prediction lstm'] = score['Average']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to improve our 24h prediction accuracy even more! Lets see how we're doing so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", 50):\n",
    "    display(results_df.sort_values(by='average score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autoregressive Models\n",
    "In the previous section, we used single-shot models that predicted multiple steps simultaneously.<br>\n",
    "Another approach we can try, is to create self-feeding model that predicts multiple steps, but one step at a time.<br>\n",
    "For example, we can write a simple AR model based on simple dense layer with the following logic:\n",
    "- gets 24h input\n",
    "- predicts 25th hour\n",
    "- predicts 26th hour based on 2-24h (from input) and 25h (from last prediction)\n",
    "- predicts 27th hour based on 3-24h (from input) and 25-26h (from last predictions)\n",
    "- and so forth... until we predict the 48th hour based on 24h (from input) and 25-47h (from last predictions)\n",
    "- returns hours 25-48<br>\n",
    "This model should be simpler to train because at each iteration the models only needs to learn single step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseAR(tf.keras.Model):\n",
    "    def __init__(self, units, in_steps, out_steps):\n",
    "        super().__init__()\n",
    "        self.in_steps = in_steps\n",
    "        self.out_steps = out_steps\n",
    "        self.units = units\n",
    "        self.conv = tf.keras.layers.Conv1D(units, activation='relu', kernel_size=(in_steps))\n",
    "        self.dense = tf.keras.layers.Dense(5)\n",
    "        self._y_features = None\n",
    "    \n",
    "    def _extract_time_features(self, data):\n",
    "        # this time we inject the relevant y features directly from the y dataset\n",
    "        # the last models didn't do it and expected the inputs to be already injected.\n",
    "        _, y, _ = tf.keras.utils.unpack_x_y_sample_weight(data)\n",
    "        self._y_features = y[:, :, :-1]\n",
    "        return data\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        self._extract_time_features(data)\n",
    "        return super().train_step(data)\n",
    "        \n",
    "    def predict_step(self, data):\n",
    "        self._extract_time_features(data)\n",
    "        return super().predict_step(data)\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        self._extract_time_features(data)\n",
    "        return super().test_step(data)\n",
    "    \n",
    "    def call(self, inputs, training=None, y_features=None):\n",
    "        if y_features is not None:\n",
    "            self._y_features = y_features[:, :, :-1]\n",
    "        \n",
    "        predictions = inputs\n",
    "        # Run the rest of the prediction steps\n",
    "        for n in range(self.out_steps):\n",
    "            # (batch, steps, features) => (batch, conv_units)\n",
    "            prediction = self.conv(predictions)\n",
    "            \n",
    "            # (batch, conv_units) => (batch, y_predicted_features + y_predicted_labels)\n",
    "            prediction = self.dense(prediction)\n",
    "            \n",
    "            # (batch, y_predicted_features + y_predicted_labels) => (batch, y_features + y_predicted_labels)\n",
    "            prediction = tf.concat([self._y_features[:,n,:], prediction[:, 0, -1:]], axis=1)\n",
    "\n",
    "            # shift the inputs tensor right with last prediction\n",
    "            predictions = tf.concat(\n",
    "                (predictions[:, 1:, :], prediction[:, tf.newaxis, :]),\n",
    "                axis=1\n",
    "            )\n",
    "            \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our model returns features and labels (instead of just the single label - class), we need to customize our metrics and loss functions to ignore irrelevant labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelMSE(tf.losses.MeanAbsoluteError):\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = y_true[:, :, -1]\n",
    "        y_pred = y_pred[:, :, -1]\n",
    "        return super().call(y_true, y_pred)\n",
    "    \n",
    "class LabelBinaryAccuracy(tf.keras.metrics.Accuracy):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = y_true[:, :, -1]\n",
    "        y_pred = y_pred[:, :, -1]\n",
    "        y_true = tf.greater_equal(y_true, 0.5)\n",
    "        y_pred = tf.greater_equal(y_pred, 0.5)\n",
    "        return super().update_state(y_true, y_pred, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ar_model():\n",
    "    return DenseAR(128, 24, 24)\n",
    "\n",
    "df = sin_normalized_df.copy()\n",
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(df)\n",
    "\n",
    "\n",
    "score = evaluate_model(\n",
    "    model_training_func=partial(_ts_model_training_func, \n",
    "                                model_creation_func=create_ar_model, \n",
    "                                input_timesteps=24 ,output_timesteps=24, epochs=20,\n",
    "                                loss_function=LabelMSE, metrics_function=LabelBinaryAccuracy, \n",
    "                                y_labels_slice=slice(None)),\n",
    "    model_evaluating_func=partial(_ts_model_evaluating_func, input_timesteps=24, output_timesteps=24, y_labels_slice=slice(None)),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION],\n",
    "    use_test_as_val=True\n",
    ")\n",
    "results_df.loc['keras 24h prediction AR dense'] = score['Average']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing! we pushed further and we're almost reaching 88%. This score seems promising, so we will evaluate it on test data<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sin_normalized_df.copy()\n",
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(df)\n",
    "\n",
    "\n",
    "score = evaluate_model(\n",
    "    model_training_func=partial(_ts_model_training_func, \n",
    "                                model_creation_func=create_ar_model, \n",
    "                                input_timesteps=24 ,output_timesteps=24, epochs=20,\n",
    "                                loss_function=LabelMSE, metrics_function=LabelBinaryAccuracy,\n",
    "                                y_labels_slice=slice(None)),\n",
    "    model_evaluating_func=partial(_ts_model_evaluating_func, input_timesteps=24, output_timesteps=24, y_labels_slice=slice(None)),\n",
    "    datasets_per_lot=[test_dataset_per_lot]\n",
    ")\n",
    "test_results_df.loc['keras 24h prediction AR dense'] = score['Average']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will try to run an LSTM model with the same autoregressive approach. We will create warm up step to prepare our lstm state, and then continue with feeding this model its own predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmAR(tf.keras.Model):\n",
    "    def __init__(self, units, out_steps):\n",
    "        super().__init__()\n",
    "        self.out_steps = out_steps\n",
    "        self.units = units\n",
    "        self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
    "        self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
    "        self.dense2 = tf.keras.layers.Dense(32, activation='relu')\n",
    "        self.dense = tf.keras.layers.Dense(5)\n",
    "        self._y_features = None\n",
    "    \n",
    "    def _extract_time_features(self, data):\n",
    "        _, y, _ = tf.keras.utils.unpack_x_y_sample_weight(data)\n",
    "        self._y_features = y[:, :, :-1]\n",
    "        return data\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        self._extract_time_features(data)\n",
    "        return super().train_step(data)\n",
    "        \n",
    "    def predict_step(self, data):\n",
    "        self._extract_time_features(data)\n",
    "        return super().predict_step(data)\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        self._extract_time_features(data)\n",
    "        return super().test_step(data)\n",
    "    \n",
    "    def warmup(self, inputs):\n",
    "        # (batch, steps, features) => (batch, lstm_units), (batch, states)\n",
    "        x, *state = self.lstm_rnn(inputs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        prediction = self.dense2(x)\n",
    "        prediction = self.dense(prediction)\n",
    "        return prediction, state\n",
    "    \n",
    "    def call(self, inputs, training=None, y_features=None):\n",
    "        if y_features is not None:\n",
    "            self._y_features = y_features[:, :, :-1]\n",
    "    \n",
    "        predictions = []\n",
    "        prediction, state = self.warmup(inputs)\n",
    "        prediction = prediction[:,-1:]\n",
    "\n",
    "        prediction = tf.concat([self._y_features[:,0,:], prediction], axis=1)\n",
    "        # Insert the first prediction\n",
    "        predictions.append(prediction)\n",
    "\n",
    "        # Run the rest of the prediction steps\n",
    "        for n in range(1, self.out_steps):\n",
    "            \n",
    "        # Use the last prediction as input.\n",
    "            x = prediction\n",
    "            # Execute one lstm step.\n",
    "            x, state = self.lstm_cell(x, states=state,\n",
    "                                      training=training)\n",
    "            \n",
    "            prediction = self.dense2(x)\n",
    "            prediction = self.dense(prediction)\n",
    "            prediction = prediction[:, -1:]\n",
    "\n",
    "            prediction = tf.concat([self._y_features[:,n,:], prediction], axis=1)\n",
    "            # Add the prediction to the output\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        # predictions.shape => (time, batch, features)\n",
    "        predictions = tf.stack(predictions)\n",
    "        \n",
    "                \n",
    "        # predictions.shape => (batch, time, features)\n",
    "        predictions = tf.transpose(predictions, [1, 0, 2])\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_ar_model():\n",
    "    return LstmAR(32, 24)\n",
    "\n",
    "df = sin_normalized_df.copy()\n",
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(df)\n",
    "\n",
    "\n",
    "score = evaluate_model(\n",
    "    model_training_func=partial(_ts_model_training_func, \n",
    "                                model_creation_func=create_lstm_ar_model, \n",
    "                                input_timesteps=24 ,output_timesteps=24, epochs=20,\n",
    "                                loss_function=LabelMSE, metrics_function=LabelBinaryAccuracy,\n",
    "                                y_labels_slice=slice(None)),\n",
    "    model_evaluating_func=partial(_ts_model_evaluating_func, input_timesteps=24, output_timesteps=24, y_labels_slice=slice(None)),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION],\n",
    "    use_test_as_val=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sin_normalized_df.copy()\n",
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(df)\n",
    "\n",
    "\n",
    "score = evaluate_model(\n",
    "    model_training_func=partial(_ts_model_training_func, \n",
    "                                model_creation_func=create_lstm_ar_model, \n",
    "                                input_timesteps=24 ,output_timesteps=24, epochs=20,\n",
    "                                loss_function=LabelMSE, metrics_function=LabelBinaryAccuracy,\n",
    "                                y_labels_slice=slice(None)),\n",
    "    model_evaluating_func=partial(_ts_model_evaluating_func, input_timesteps=24, output_timesteps=24, y_labels_slice=slice(None)),\n",
    "    datasets_per_lot=[test_dataset_per_lot]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw before, LSTM could potentialy hide important features such as y-features (day/week sin/cos), we can feed our dense layer directly with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmAR2(tf.keras.Model):\n",
    "    def __init__(self, units, out_steps):\n",
    "        super().__init__()\n",
    "        self.out_steps = out_steps\n",
    "        self.units = units\n",
    "        self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
    "        # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\n",
    "        self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
    "        self.dense2 = tf.keras.layers.Dense(32, activation='relu')\n",
    "        self.dense = tf.keras.layers.Dense(5)\n",
    "        self._y_features = None\n",
    "    \n",
    "    def _extract_time_features(self, data):\n",
    "        _, y, _ = tf.keras.utils.unpack_x_y_sample_weight(data)\n",
    "        self._y_features = y[:, :, :-1]\n",
    "        return data\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        self._extract_time_features(data)\n",
    "        return super().train_step(data)\n",
    "        \n",
    "    def predict_step(self, data):\n",
    "        self._extract_time_features(data)\n",
    "        return super().predict_step(data)\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        self._extract_time_features(data)\n",
    "        return super().test_step(data)\n",
    "    \n",
    "    def warmup(self, inputs):\n",
    "        # (batch, steps, features) => (batch, lstm_units), (batch, states)\n",
    "        x, *state = self.lstm_rnn(inputs)\n",
    "        # (batch, features) => (batch, y_features+features)\n",
    "        x = tf.concat([self._y_features[:,0,:], x], axis=1)\n",
    "        prediction = self.dense2(x)\n",
    "        prediction = self.dense(prediction)\n",
    "        return prediction, state\n",
    "    \n",
    "    def call(self, inputs, training=None, y_features=None):\n",
    "        if y_features is not None:\n",
    "            self._y_features = y_features[:, :, :-1]\n",
    "        \n",
    "        # Use a TensorArray to capture dynamically unrolled outputs.\n",
    "        predictions = []\n",
    "        # Initialize the lstm state\n",
    "        prediction, state = self.warmup(inputs)\n",
    "        prediction = prediction[:,-1:]\n",
    "\n",
    "        prediction = tf.concat([self._y_features[:,0,:], prediction], axis=1)\n",
    "        # Insert the first prediction\n",
    "        predictions.append(prediction)\n",
    "\n",
    "        # Run the rest of the prediction steps\n",
    "        for n in range(1, self.out_steps):\n",
    "            \n",
    "        # Use the last prediction as input.\n",
    "            x = prediction\n",
    "            # Execute one lstm step.\n",
    "            x, state = self.lstm_cell(x, states=state,\n",
    "                                      training=training)\n",
    "            \n",
    "            # Convert the lstm output to a prediction.\n",
    "#             prediction = self.dense2(x)\n",
    "#             prediction = self.dense3(x)\n",
    "            x = tf.concat([self._y_features[:,n,:], x], axis=1)\n",
    "            prediction = self.dense2(x)\n",
    "            prediction = self.dense(prediction)\n",
    "            prediction = prediction[:, -1:]\n",
    "\n",
    "            prediction = tf.concat([self._y_features[:,n,:], prediction], axis=1)\n",
    "            # Add the prediction to the output\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        # predictions.shape => (time, batch, features)\n",
    "        predictions = tf.stack(predictions)\n",
    "        \n",
    "                \n",
    "        # predictions.shape => (batch, time, features)\n",
    "        predictions = tf.transpose(predictions, [1, 0, 2])\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm2_ar_model():\n",
    "    return LstmAR2(32, 24)\n",
    "\n",
    "df = sin_normalized_df.copy()\n",
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(df)\n",
    "\n",
    "\n",
    "score = evaluate_model(\n",
    "    model_training_func=partial(_ts_model_training_func, \n",
    "                                model_creation_func=create_lstm2_ar_model, \n",
    "                                input_timesteps=24 ,output_timesteps=24, epochs=20,\n",
    "                                loss_function=LabelMSE, metrics_function=LabelBinaryAccuracy,\n",
    "                                y_labels_slice=slice(None)),\n",
    "    model_evaluating_func=partial(_ts_model_evaluating_func, input_timesteps=24, output_timesteps=24, y_labels_slice=slice(None)),\n",
    "    datasets_per_lot=train_and_validation_datasets_per_lot,\n",
    "    detailed=True,\n",
    "    row_names=[f'{m}/{y}' for m, y in MONTHS_AND_YEARS_FOR_TRAIN_AND_VALIDATION],\n",
    "    use_test_as_val=True\n",
    ")\n",
    "results_df.loc['keras 24h prediction AR LSTM'] = score['Average']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We improved a little bit, still behind the CNN-Dense AR model. Let's evaluate this model on test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sin_normalized_df.copy()\n",
    "train_and_validation_datasets_per_lot, test_dataset_per_lot = create_train_validation_test_datasets(df)\n",
    "\n",
    "\n",
    "score = evaluate_model(\n",
    "    model_training_func=partial(_ts_model_training_func, \n",
    "                                model_creation_func=create_lstm2_ar_model, \n",
    "                                input_timesteps=24 ,output_timesteps=24, epochs=20,\n",
    "                                loss_function=LabelMSE, metrics_function=LabelBinaryAccuracy,\n",
    "                                y_labels_slice=slice(None)),\n",
    "    model_evaluating_func=partial(_ts_model_evaluating_func, input_timesteps=24, output_timesteps=24, y_labels_slice=slice(None)),\n",
    "    datasets_per_lot=[test_dataset_per_lot]\n",
    ")\n",
    "test_results_df.loc['keras 24h prediction AR LSTM'] = score['Average']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Results\n",
    "We tackled our data with lots of classification approach. Let's summarize the results!\n",
    "### Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", 50):\n",
    "    display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", 50):\n",
    "    display(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy and Anomalies\n",
    "We can compare our predictions to the true values to find special patterns and anomalies which could help us in the future improve.<br>\n",
    "First, let's take our sklearn best classifier we found before and train them with all our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_dataset_per_lot = create_train_validation_test_datasets(enriched_df)\n",
    "\n",
    "classic_models = {lot: model[0](**model[1]) for lot, model in lot_to_best_clf.items()}\n",
    "for lot, lot_df in tqdm(test_dataset_per_lot.items()):\n",
    "    x, y = split_df_to_x_y(lot_df[0])\n",
    "    classic_models[lot].fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can create special dataframe with success column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = dict()\n",
    "for lot_name, lot_df in enriched_df.groupby('lot'):\n",
    "    df = lot_df.copy()\n",
    "    x, y = split_df_to_x_y(lot_df.drop(columns=['lot', 'datetime']))\n",
    "    y_predicts = classic_models[lot_name].predict(x)\n",
    "    df['prediction'] = y_predicts\n",
    "    df.loc[df['prediction'] == df['class'], 'success'] = 1\n",
    "    df.loc[df['prediction'] != df['class'], 'success'] = 0\n",
    "    df['date'] = df['datetime'].dt.normalize()\n",
    "    df['week_first_day'] = (\n",
    "        ((df['date'] - FIRST_DAY_OF_FIRST_WHOLE_WEEK).dt.days / 7)\n",
    "        .astype(int)\n",
    "        .apply(lambda week_idx: FIRST_DAY_OF_FIRST_WHOLE_WEEK + pd.to_timedelta(timedelta(weeks=week_idx)))\n",
    "    )\n",
    "\n",
    "    df['day_hour'] = df['date'].dt.day_name() + '-' + df['datetime'].dt.hour.astype(str).str.zfill(2)\n",
    "\n",
    "    \n",
    "    predict_df[lot_name] = df\n",
    "    \n",
    "predict_with_lot_name = predict_df.copy()\n",
    "for lot in LOT_NAMES:\n",
    "    predict_with_lot_name[lot]['lot'] = lot\n",
    "    predict_with_lot_name[lot]\n",
    "\n",
    "predict_with_lot_name = pd.concat(predict_with_lot_name.values())\n",
    "predict_with_lot_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Accuracy\n",
    "Just like we did at the beginning, we can use our data exploration visualizations to learn about our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(LOT_NAMES), 1, figsize=(15, 8 * len(LOT_NAMES)), sharey=True)\n",
    "fig.suptitle('Model Accuracy Per Hour', fontsize=22, y=0.895)\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "for i, lot in enumerate(LOT_NAMES):\n",
    "    df = predict_df[lot]\n",
    "    ax = axes[i]\n",
    "    plot = sns.scatterplot(\n",
    "        ax=ax,\n",
    "        palette=GREEN_RED_PALETTE,\n",
    "        legend=False,\n",
    "        x='day_hour',\n",
    "        y='week_first_day',\n",
    "        hue='success',\n",
    "        s=10,\n",
    "        data=df\n",
    "    )\n",
    "    ax.set_title(lot)\n",
    "\n",
    "for ax in axes:\n",
    "    for i, label in enumerate(ax.get_xticklabels()):\n",
    "        if i % 4 == 0:\n",
    "            label.set_rotation(90)\n",
    "        else:\n",
    "            label.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On most of the parking lots, we can spot some patterns of missed predictions. It seems as the pattern is repeated on certain hours and days.<br>\n",
    "Let's continue with our exploration and look for weekly patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(13, 8))\n",
    "fig.suptitle('Average Accuracy Per Hour In The Week', fontsize=22)\n",
    "gs = fig.add_gridspec(3, 3)\n",
    "axes = [fig.add_subplot(gs[0, :])]\n",
    "for i in range(len(LOT_NAMES)):\n",
    "    axes.append(fig.add_subplot(gs[1 + i // 3, i % 3]))\n",
    "\n",
    "ax = axes[0]\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    x='day_hour',\n",
    "    y='success',\n",
    "    data=predict_with_lot_name\n",
    ")\n",
    "ax.set_title('All Lots Combined')\n",
    "\n",
    "for i, lot in enumerate(LOT_NAMES):\n",
    "    ax = axes[i + 1]\n",
    "    g = sns.lineplot(\n",
    "        ax=ax,\n",
    "        x='day_hour',\n",
    "        y='success',\n",
    "        data=predict_with_lot_name[predict_with_lot_name['lot'] == lot]\n",
    "    )\n",
    "    ax.set_title(lot)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_ylim(bottom=0.5, top=1)\n",
    "    for i, label in enumerate(ax.get_xticklabels()):\n",
    "        if i % 8 == 0:\n",
    "            label.set_rotation(90)\n",
    "        else:\n",
    "            label.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intersting. We definitely see some hourly patterns here! Let's zoom in and group by the hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(13, 8))\n",
    "fig.suptitle('Average Accuracy Per Hour', fontsize=22)\n",
    "gs = fig.add_gridspec(3, 3)\n",
    "axes = [fig.add_subplot(gs[0, :])]\n",
    "for i in range(len(LOT_NAMES)):\n",
    "    axes.append(fig.add_subplot(gs[1 + i // 3, i % 3]))\n",
    "\n",
    "ax = axes[0]\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    x='hour',\n",
    "    y='success',\n",
    "    data=predict_with_lot_name\n",
    ")\n",
    "ax.set_title('All Lots Combined')\n",
    "\n",
    "for i, lot in enumerate(LOT_NAMES):\n",
    "    ax = axes[i + 1]\n",
    "    g = sns.lineplot(\n",
    "        ax=ax,\n",
    "        x='hour',\n",
    "        y='success',\n",
    "        data=predict_with_lot_name[predict_with_lot_name['lot'] == lot]\n",
    "    )\n",
    "    ax.set_title(lot)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_ylim(bottom=0.5, top=1)\n",
    "    for i, label in enumerate(ax.get_xticklabels()):\n",
    "        label.set_rotation(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we got it! We can clearly see the unique patterns each lot has!<br>Let's see if we can spot any anomalies over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_predict_df = (\n",
    "    predict_with_lot_name\n",
    "    .groupby(by=['week_first_day', 'lot'])\n",
    "    .agg({'success': 'mean'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(13, 8))\n",
    "fig.suptitle('Average Accuracy Per Week Over Time', fontsize=22)\n",
    "gs = fig.add_gridspec(3, 3)\n",
    "axes = [fig.add_subplot(gs[0, :])]\n",
    "for i in range(len(LOT_NAMES)):\n",
    "    axes.append(fig.add_subplot(gs[1 + i // 3, i % 3]))\n",
    "\n",
    "ax = axes[0]\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    x='week_first_day',\n",
    "    marker='o',\n",
    "    y='success',\n",
    "    data=weekly_predict_df\n",
    ")\n",
    "ax.set_title('All Lots Combined')\n",
    "\n",
    "for i, lot in enumerate(LOT_NAMES):\n",
    "    ax = axes[i + 1]\n",
    "    sns.lineplot(\n",
    "        ax=ax,\n",
    "        x='week_first_day',\n",
    "        marker='o',\n",
    "        y='success',\n",
    "        data=weekly_predict_df[weekly_predict_df['lot'] == lot]\n",
    "    )\n",
    "    ax.set_title(lot)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_ylim(bottom=0, top=1)\n",
    "    for i, label in enumerate(ax.get_xticklabels()):\n",
    "        label.set_rotation(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_predict_df[weekly_predict_df['lot'] == 'Basel'].sort_values(by=['success']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find some interesting anomalies on SOME of the data. For example the week of 21/03/20's was the beginning of the first lockdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using our Deep learning models\n",
    "We can sift out some minor anomalies if we check our DNN models with sklearn's models.<br>\n",
    "First, we need to run and evaluate our model on all our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ar_model():\n",
    "    return DenseAR(128, 24, 24)\n",
    "def _split_x_y(batch):\n",
    "    x = batch[:, :24, :]\n",
    "    y = batch[:, 24:, :] \n",
    "    x.set_shape([None, 24, None])\n",
    "    y.set_shape([None, 24, None])\n",
    "    return x, y\n",
    "    \n",
    "models = {}\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2, mode='min')\n",
    "                                                  \n",
    "for lot_name, lot_df in tqdm(sin_normalized_df.groupby('lot')):\n",
    "    lot_df = lot_df[['day sin', 'day cos', 'week sin', 'week cos', 'class']]\n",
    "    arr = np.array(lot_df, dtype=np.float32)\n",
    "    ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "        arr,\n",
    "        targets=None,\n",
    "        sequence_stride=1,\n",
    "        sequence_length=48, \n",
    "        shuffle=True,\n",
    "        batch_size=32\n",
    "    )\n",
    "    ds = ds.map(_split_x_y)\n",
    "    model = create_ar_model()\n",
    "    model.compile(loss=LabelMSE(), \n",
    "                  optimizer=tf.optimizers.Adam(),\n",
    "                  metrics=[LabelBinaryAccuracy()])\n",
    "    model.fit(ds, epochs=20, verbose=1, callbacks=[early_stopping])\n",
    "    models[lot_name] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can created unified dataframe with sklearn's predictions and see where both of the models did not succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df2 = dict()\n",
    "for lot_name, lot_df in tqdm(sin_normalized_df.groupby('lot')):   \n",
    "    lot_df = lot_df[['day sin', 'day cos', 'week sin', 'week cos', 'class', 'datetime']]\n",
    "    ts = lot_df.pop('datetime').view('int64')\n",
    "    \n",
    "    arr = np.array(lot_df, dtype=np.float32)\n",
    "    ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "        arr,\n",
    "        targets=None,\n",
    "        sequence_stride=1,\n",
    "        sequence_length=48, \n",
    "        shuffle=False, # Do not mix up batches\n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    datetime_arr = np.array(pd.DataFrame(ts, columns=['datetime']), dtype=np.int64)\n",
    "    datetime_ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "        datetime_arr,\n",
    "        targets=None,\n",
    "        sequence_stride=1,\n",
    "        sequence_length=48, \n",
    "        shuffle=False, # Do not mix up batches\n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    batches = list() \n",
    "    for dt in datetime_ds:\n",
    "        batches.append(dt[:, 24:, :])\n",
    "        \n",
    "    batch_to_datetime = tf.concat(batches, axis=0)\n",
    "    \n",
    "    ds = ds.map(_split_x_y)\n",
    "    model = models[lot_name]\n",
    "    predictions = model.predict(ds)\n",
    "    predictions = tf.concat([predictions, batch_to_datetime], axis=2)\n",
    "    data = tf.concat(tf.unstack(predictions, axis=0), axis=0).numpy()\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['day sin', 'day cos', 'week sin', 'week cos', 'prediction_dnn', 'datetime_s'])\n",
    "    df['prediction_dnn'] = (df['prediction_dnn'] >= 0.5).astype(np.float32)\n",
    "    df = df[['prediction_dnn', 'datetime_s']]\n",
    "\n",
    "    df = df.groupby(by=['datetime_s']).agg({'prediction_dnn': 'mean'}).reset_index()\n",
    "    df['prediction_dnn'] = (df['prediction_dnn'] >= 0.5).astype(np.float32)\n",
    "\n",
    "\n",
    "    df2 = predict_df[lot_name].copy()\n",
    "    df2['datetime_s'] = df2['datetime'].view('int64')\n",
    "\n",
    "    df = df.merge(df2, on=['datetime_s'], how='inner')\n",
    "    df.loc[df['prediction_dnn'] == df['class'], 'success_dnn'] = 1\n",
    "    df.loc[df['prediction_dnn'] != df['class'], 'success_dnn'] = 0\n",
    "    df['date'] = df['datetime'].dt.normalize()\n",
    "    df['week_first_day'] = (\n",
    "        ((df['date'] - FIRST_DAY_OF_FIRST_WHOLE_WEEK).dt.days / 7)\n",
    "        .astype(int)\n",
    "        .apply(lambda week_idx: FIRST_DAY_OF_FIRST_WHOLE_WEEK + pd.to_timedelta(timedelta(weeks=week_idx)))\n",
    "    )\n",
    "\n",
    "    df['day_hour'] = df['date'].dt.day_name() + '-' + df['datetime'].dt.hour.astype(str).str.zfill(2)\n",
    "    df['any_success'] = (df['success'] + df['success_dnn'] > 0).astype(np.float32)\n",
    "    df.pop('datetime_s') \n",
    "    \n",
    "    \n",
    "    predict_df2[lot_name] = df\n",
    "\n",
    "predict2_with_lot_name = predict_df2.copy()\n",
    "for lot in LOT_NAMES:\n",
    "    predict2_with_lot_name[lot]['lot'] = lot\n",
    "    predict2_with_lot_name[lot]\n",
    "\n",
    "predict2_with_lot_name = pd.concat(predict2_with_lot_name.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, lets run the same visualizations, this time on `any_success` so we will get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(LOT_NAMES), 1, figsize=(15, 8 * len(LOT_NAMES)), sharey=True)\n",
    "fig.suptitle('Model Accuracy Per Hour', fontsize=22, y=0.895)\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "for i, lot in enumerate(LOT_NAMES):\n",
    "    df = predict_df2[lot]\n",
    "    ax = axes[i]\n",
    "    plot = sns.scatterplot(\n",
    "        ax=ax,\n",
    "        palette=GREEN_RED_PALETTE,\n",
    "        legend=False,\n",
    "        x='day_hour',\n",
    "        y='week_first_day',\n",
    "        hue='any_success',\n",
    "        s=10,\n",
    "        data=df\n",
    "    )\n",
    "    ax.set_title(lot)\n",
    "\n",
    "for ax in axes:\n",
    "    for i, label in enumerate(ax.get_xticklabels()):\n",
    "        if i % 4 == 0:\n",
    "            label.set_rotation(90)\n",
    "        else:\n",
    "            label.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we can see that there is less random noise and we can definitely spot the existance of patterns. Now let's focus on week and hourly patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(13, 8))\n",
    "fig.suptitle('Average Accuracy Per Hour In The Week', fontsize=22)\n",
    "gs = fig.add_gridspec(3, 3)\n",
    "axes = [fig.add_subplot(gs[0, :])]\n",
    "for i in range(len(LOT_NAMES)):\n",
    "    axes.append(fig.add_subplot(gs[1 + i // 3, i % 3]))\n",
    "\n",
    "ax = axes[0]\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    x='day_hour',\n",
    "    y='any_success',\n",
    "    data=predict2_with_lot_name\n",
    ")\n",
    "ax.set_title('All Lots Combined')\n",
    "\n",
    "for i, lot in enumerate(LOT_NAMES):\n",
    "    ax = axes[i + 1]\n",
    "    g = sns.lineplot(\n",
    "        ax=ax,\n",
    "        x='day_hour',\n",
    "        y='any_success',\n",
    "        data=predict2_with_lot_name[predict2_with_lot_name['lot'] == lot]\n",
    "    )\n",
    "    ax.set_title(lot)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_ylim(bottom=0.5, top=1)\n",
    "    for i, label in enumerate(ax.get_xticklabels()):\n",
    "        if i % 8 == 0:\n",
    "            label.set_rotation(90)\n",
    "        else:\n",
    "            label.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(13, 8))\n",
    "fig.suptitle('Average Accuracy Per Hour', fontsize=22)\n",
    "gs = fig.add_gridspec(3, 3)\n",
    "axes = [fig.add_subplot(gs[0, :])]\n",
    "for i in range(len(LOT_NAMES)):\n",
    "    axes.append(fig.add_subplot(gs[1 + i // 3, i % 3]))\n",
    "\n",
    "ax = axes[0]\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    x='hour',\n",
    "    y='any_success',\n",
    "    data=predict2_with_lot_name\n",
    ")\n",
    "ax.set_title('All Lots Combined')\n",
    "\n",
    "for i, lot in enumerate(LOT_NAMES):\n",
    "    ax = axes[i + 1]\n",
    "    g = sns.lineplot(\n",
    "        ax=ax,\n",
    "        x='hour',\n",
    "        y='any_success',\n",
    "        data=predict2_with_lot_name[predict2_with_lot_name['lot'] == lot]\n",
    "    )\n",
    "    ax.set_title(lot)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_ylim(bottom=0.5, top=1)\n",
    "    for i, label in enumerate(ax.get_xticklabels()):\n",
    "        label.set_rotation(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we go! this time we can see that Basel and Asuta were harder to predict specifically very early at the morning, when someone leaves its parking spot and there is barely traffic, and around 6-7pm, when people come back from work and the parking lots are queuing up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_predict2_df = (\n",
    "    predict2_with_lot_name\n",
    "    .groupby(by=['week_first_day', 'lot'])\n",
    "    .agg({'any_success': 'mean'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(13, 8))\n",
    "fig.suptitle('Average Accuracy Per Week Over Time', fontsize=22)\n",
    "gs = fig.add_gridspec(3, 3)\n",
    "axes = [fig.add_subplot(gs[0, :])]\n",
    "for i in range(len(LOT_NAMES)):\n",
    "    axes.append(fig.add_subplot(gs[1 + i // 3, i % 3]))\n",
    "\n",
    "ax = axes[0]\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    x='week_first_day',\n",
    "    marker='o',\n",
    "    y='any_success',\n",
    "    data=weekly_predict2_df\n",
    ")\n",
    "ax.set_title('All Lots Combined')\n",
    "\n",
    "for i, lot in enumerate(LOT_NAMES):\n",
    "    ax = axes[i + 1]\n",
    "    sns.lineplot(\n",
    "        ax=ax,\n",
    "        x='week_first_day',\n",
    "        marker='o',\n",
    "        y='any_success',\n",
    "        data=weekly_predict2_df[weekly_predict2_df['lot'] == lot]\n",
    "    )\n",
    "    ax.set_title(lot)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_ylim(bottom=0.7, top=1)\n",
    "    for i, label in enumerate(ax.get_xticklabels()):\n",
    "        label.set_rotation(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over time, we can spot some anomalies usually around holidays. More over, we can see some spikes on uncertainty around April 2020, September 2020 and December 2020 - months with heavy covid restrictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Words\n",
    "We had great time working on this intersting project! Each and every aspect of it has taught us new skills. We practiced data visualizations, worked with classifiers and tweaked some deep learning models. We also learned techniques to cross-validate our results to reduce bias.<br>\n",
    "Even though we decided to end this project here, we believe there are many ways we can continue exploring from here. We might be able to find correlations with other data such as NLP analysis of news. There is also much room for improvement in our models - we only tested few configurations with not-so-effective computational efficiency. We could push our anomaly detection even further and create 2nd degree models that predicts anomalies using our trained models!<br>\n",
    "Since we're staying in Tel-Aviv, we will keep collecting data and continue this project and on our free time. We already have almost two years of data, it would be worth checking it again once we have even more data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
